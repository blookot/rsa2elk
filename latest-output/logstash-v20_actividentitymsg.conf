# Config file generated by RSA2ELK, see https://github.com/blookot/rsa2elk 
# Author: Vincent Maury
# Check all Netwitness parsers: https://github.com/netwitness/nw-logparsers/tree/master/devices/ (license: Apache 2.0)
# Check this link to search for source configuration guides: https://rsa.jiveon.com/community/products/netwitness/integrations/event-sources

##########
# CAUTION: check the "path" in input and "dictionary_path" in filter, as well as the "template" path in the elasticsearch output or "path" in the file output
##########

input {
#	syslog {
#		port => 514
#	}
#	file {
#		path => "/var/log/example.log"
#		start_position => "beginning"
#		sincedb_path => "/dev/null"
#	}
	generator {
		count => 1
		message => "a log line to test out"
	}
#	kafka {
#		codec => "json"
#		bootstrap_servers => "192.168.30.13:9092"
#		topics => ["mytopic"]
#		security_protocol => "SSL"
#		ssl_key_password => "{ssl_password}"
#		ssl_keystore_location => "/{keystore-absolute-path}"
#		ssl_keystore_password => "{keystore_password}"
#		ssl_truststore_location => "/{truststore-absolute-path}"
#		ssl_truststore_password => "{truststore_password}"
#	}
}

# Renaming a couple of fields
filter {
	mutate {
		rename => {
			"message" => "[event][original]"
			"host" => "[logstash][host]"
		}
	}
}

# Setting the device name and group
filter {
	mutate {
		add_field => {
			"[observer][product]" => "actividentity"
			"[observer][name]" => "ActivIdentity AAA Server"
			"[observer][type]" => "Access Control"
		}
	}
}


# One single filter block for all headers and messages
filter {

################## HEADERS ##################

	# HEADER 0001
	# line in RSA: %ActivIdentity: <messageid>||<!payload>
	if ![logstash][headerfound] {
		dissect {
			mapping => { "[event][original]" => "%ActivIdentity: %{messageid}||%{message}" }
			id => "header-0001"
			add_field => {
				"[rsa][header][id]" => "0001"
				"[rsa][message][id2]" => "%{messageid}"
				"[logstash][headerfound]" => true
			}
		}
	}



################## MsgId2 to Parser ##################

	translate {
		field => "[rsa][message][id2]"
		destination => "[logstash][msgparser][id]"
		dictionary_path => "msgid2parserid-v20_actividentitymsg.json"
		fallback => ""
		override => true
	}


################## MESSAGES ##################

	# PARSER msgParserId0
	# line in RSA:  <fld1>||<saddr>||<event_time>||<fld2>||<username>||<group>||<daddr>||<result>||<fld3>||<fld4>||<fld5>
	if [logstash][msgparser][id] == "msgParserId0" {
		dissect {
			mapping => { "message" => "%{fld1}||%{saddr}||%{event_time}||%{fld2}||%{username}||%{group}||%{daddr}||%{result}||%{fld3}||%{fld4}||%{fld5}" }
			id => "msgParserId0"
			add_field => {
				"[logstash][messagefound]" => true
			}
		}
	}
	# PARSER msgParserId1
	# line in RSA:    <username>||<event_time>||<fld1>||<action>||<info>||<fld2>||<fld3>||<fld4>||<fld5>
	else if [logstash][msgparser][id] == "msgParserId1" {
		dissect {
			mapping => { "message" => "%{username}||%{event_time}||%{fld1}||%{action}||%{info}||%{fld2}||%{fld3}||%{fld4}||%{fld5}" }
			id => "msgParserId1"
			add_field => {
				"[logstash][messagefound]" => true
			}
		}
	}
	# PARSER msgParserId2
	# line in RSA:    <username>||<event_time>||<fld1>||<action>||<info>||<fld2>||<fld4>||<fld5>||<fld6>
	else if [logstash][msgparser][id] == "msgParserId2" {
		dissect {
			mapping => { "message" => "%{username}||%{event_time}||%{fld1}||%{action}||%{info}||%{fld2}||%{fld4}||%{fld5}||%{fld6}" }
			id => "msgParserId2"
			add_field => {
				"[logstash][messagefound]" => true
			}
		}
	}
	# PARSER msgParserId3
	# line in RSA: <fld1>||<saddr>||<event_time>||<fld2>||<username>||<daddr>||<fld3>||<fld4>||<fld5>||<fld6>
	else if [logstash][msgparser][id] == "msgParserId3" {
		dissect {
			mapping => { "message" => "%{fld1}||%{saddr}||%{event_time}||%{fld2}||%{username}||%{daddr}||%{fld3}||%{fld4}||%{fld5}||%{fld6}" }
			id => "msgParserId3"
			add_field => {
				"[logstash][messagefound]" => true
			}
		}
	}


################## END OF MESSAGES ##################

# End of the filter block
}

# Enrich events using VALUEMAP
filter {
	translate {
		field => "[info]"
		destination => "[info]"
		dictionary => {
			"26000" => "Unlock Device PIN Code"
			"26001" => "Unlock And Reset Number Of Tries"
			"26002" => "Resynchronize"
			"26003" => "Lock"
			"26004" => "Activate Temporary Password"
			"26005" => "Deactivate Temporary Password"
			"26006" => "LDAP options"
			"26007" => "General Option"
			"26008" => "Helpdesk Options"
			"26009" => "Succeeded"
			"26010" => "Failed"
			"26011" => "Begin"
			"26012" => "Stopped By User"
			"26013" => "Common Repository Settings"
			"26014" => "Authentication Devices"
			"26015" => "Audit Settings"
			"26016" => "Windows Strong Login Settings"
			"26017" => "User Management Settings"
			"26018" => "Replace"
			"26019" => "Deactivate SMS Backup Authentication"
			"26020" => "Activate SMS Backup Authentication"
			"26021" => "SMS Gateway Options"
			"26022" => "Synchronous Authentication And Resynchronization"
		}
		fallback => ""
		override => true
	}
}
filter {
	translate {
		field => "[action]"
		destination => "[action]"
		dictionary => {
			"15277" => "LoginFailure"
			"24000" => "Create"
			"24001" => "Update"
			"24002" => "Delete"
			"24003" => "ChangePassword"
			"24004" => "Assign"
			"24005" => "Consolidate"
			"24006" => "Helpdesk"
			"24007" => "Export"
			"24008" => "Unassign"
			"24009" => "fldPool"
			"24010" => "Clear"
			"24011" => "ChangeRepository"
			"24012" => "Import"
			"24013" => "Initialization"
			"24014" => "Retrieve"
			"24015" => "Enroll"
			"24016" => "fldPoolConfigurationUpdate"
			"24017" => "Test"
			"24018" => "RetrieveDevicesCredentials"
			"24019" => "Repair"
			"24020" => "SecurityQuestions"
			"24021" => "Challenge/Response"
			"24022" => "LDAPResponse"
			"24023" => "Synchronous"
			"24024" => "Asynchronous"
			"24025" => "RetrieveSingleCredential"
			"24026" => "GetPINCode"
		}
		fallback => ""
		override => true
	}
}


output {
#	if [logstash][headerfound] and [logstash][messagefound] {
#		elasticsearch {
#			hosts => ["https://elasticxxxxxx"]
#			index => "%{[observer][product]}-%{+YYYY.MM.dd}"
#			user => "logstash"
#			password => "abc"	# Better use keystore, cf https://www.elastic.co/guide/en/logstash/master/keystore.html
#			manage_template => true
#			template => "es-mapping-v20_actividentitymsg.json"
#			template_name => "actividentity_template"
#			template_overwrite => true
#		}
#	} else {
#		# using a file output for logs that were not parsed correctly
#		# should you chose to send it to elasticsearch, please read https://discuss.elastic.co/t/latency-with-2-elasticsearch-systems/170074/2
#		file { path => "failed_logs-%{[observer][product]}-%{+YYYY-MM-dd}" }
#	}
	stdout {
		codec => rubydebug
	}
}

# Config file generated by RSA2ELK, see https://github.com/blookot/rsa2elk 
# Author: Vincent Maury
# Check all Netwitness parsers: https://github.com/netwitness/nw-logparsers/tree/master/devices/ (license: Apache 2.0)
# Check this link to search for source configuration guides: https://rsa.jiveon.com/community/products/netwitness/integrations/event-sources

##########
# CAUTION: check the "path" in input and "dictionary_path" in filter, as well as the "template" path in the elasticsearch output or "path" in the file output
##########

input {
#	syslog {
#		port => 514
#	}
#	file {
#		path => "/var/log/example.log"
#		start_position => "beginning"
#		sincedb_path => "/dev/null"
#	}
	generator {
		count => 1
		message => "a log line to test out"
	}
#	kafka {
#		codec => "json"
#		bootstrap_servers => "192.168.30.13:9092"
#		topics => ["mytopic"]
#		security_protocol => "SSL"
#		ssl_key_password => "{ssl_password}"
#		ssl_keystore_location => "/{keystore-absolute-path}"
#		ssl_keystore_password => "{keystore_password}"
#		ssl_truststore_location => "/{truststore-absolute-path}"
#		ssl_truststore_password => "{truststore_password}"
#	}
}

# Renaming a couple of fields
filter {
	mutate {
		rename => {
			"message" => "[event][original]"
			"host" => "[logstash][host]"
		}
	}
}



# One single filter block for all headers and messages
filter {

################## HEADERS ##################

	# HEADER 0001
	# line in RSA: <month> <day> <time> CEF:0|Netwitness|Informer|<version>|Action|<severity>|<hfld81>externalId=<hfld1> proto=<hfld2> art=<hfld3><hfld82>act=<messageid> <!payload:month>
	# Parsing error: Couldn't parse because of 2 adjacent fields like <fld1><fld2>
	# HEADER 0004
	# line in RSA: <month> <day> <time> CEF:0|Netwitness|Informer|<version>|<msgIdPart1> <msgIdPart2> <msgIdPart3> <msgIdPart4>|<!payload:month>
	if ![logstash][headerfound] {
		grok {
			match => { "[event][original]" => "^(?<message>(?<month>[^\s]*)[\s]+(?<day>[^\s]*)[\s]+(?<time>[^\s]*)[\s]+CEF:0\|Netwitness\|Informer\|(?<version>[^\|]*)\|(?<msgIdPart1>[^\s]*)[\s]+(?<msgIdPart2>[^\s]*)[\s]+(?<msgIdPart3>[^\s]*)[\s]+(?<msgIdPart4>[^\|]*)\|(?<payload>.*))$" }
			id => "header-0004"
			add_field => {
				"[rsa][header][id]" => "0004"
				"[rsa][message][id2]" => "%{msgIdPart1}_%{msgIdPart2}_%{msgIdPart3}_%{msgIdPart4}"
				"[logstash][headerfound]" => true
			}
		}
	}
	# HEADER 0003
	# line in RSA: <month> <day> <time> CEF:0|Netwitness|Informer|<version>|<msgIdPart1> <msgIdPart2>|<!payload:month>
	if ![logstash][headerfound] {
		grok {
			match => { "[event][original]" => "^(?<message>(?<month>[^\s]*)[\s]+(?<day>[^\s]*)[\s]+(?<time>[^\s]*)[\s]+CEF:0\|Netwitness\|Informer\|(?<version>[^\|]*)\|(?<msgIdPart1>[^\s]*)[\s]+(?<msgIdPart2>[^\|]*)\|(?<payload>.*))$" }
			id => "header-0003"
			add_field => {
				"[rsa][header][id]" => "0003"
				"[rsa][message][id2]" => "%{msgIdPart1}_%{msgIdPart2}"
				"[logstash][headerfound]" => true
			}
		}
	}
	# HEADER 0002
	# line in RSA: <month> <day> <time> CEF:0|Netwitness|Informer|<version>|<messageid>|<!payload:month>
	if ![logstash][headerfound] {
		grok {
			match => { "[event][original]" => "^(?<message>(?<month>[^\s]*)[\s]+(?<day>[^\s]*)[\s]+(?<time>[^\s]*)[\s]+CEF:0\|Netwitness\|Informer\|(?<version>[^\|]*)\|(?<messageid>[^\|]*)\|(?<payload>.*))$" }
			id => "header-0002"
			add_field => {
				"[rsa][header][id]" => "0002"
				"[rsa][message][id2]" => "%{messageid}"
				"[logstash][headerfound]" => true
			}
		}
	}
	# HEADER 0005
	# line in RSA: <month> <day> <time> CEF:0|Netwitness|Informer|<hversion>|<hevent_type>|<hseverity>|<hfld81>externalId=<hoperation_id> proto=<hfld14> art=<hfld12>act=<haction> rt=<messageid><!payload:month>
	# Parsing error: Couldn't parse because of 2 adjacent fields like <fld1><fld2>
	# HEADER 0006
	# line in RSA: %NICWIN-<hfld1>-NetWitness Informer_<messageid>_Informer Web: <!payload>
	if ![logstash][headerfound] {
		dissect {
			mapping => { "[event][original]" => "%NICWIN-%{hfld1}-NetWitness Informer_%{messageid}_Informer Web: %{message}" }
			id => "header-0006"
			add_field => {
				"[rsa][header][id]" => "0006"
				"[rsa][message][id2]" => "%{messageid}"
				"[logstash][headerfound]" => true
			}
		}
	}



################## MsgId2 to Parser ##################

	translate {
		field => "[rsa][message][id2]"
		destination => "[logstash][msgparser][id]"
		dictionary_path => "msgid2parserid-netwitnessmsg.json"
		fallback => ""
		override => true
	}


################## MESSAGES ##################

	if [logstash][msgparser][id] == "1000" {
		# MESSAGE USER_LOGIN_FAILED
		# line in RSA: <@ec_subject:User><@ec_activity:Logon><@ec_theme:Authentication><@ec_outcome:Failure><@fld61:*PARMVAL(event_user)><@:*SYSVAL($MSGID,$ID1)><@msg:*PARMVAL($MSG)><@event_time:*EVNTTIME($MSG,'%B %D %N:%U:%O %W',fld35)><event_log>,<fld1>,<fld34> <fld35>,<id>,<event_source>,<event_user>,<event_type>,<event_computer>,<category>,<fld2>,User <username> attempted to login but failed.
		if ![logstash][messagefound] {
			dissect {
				mapping => { "message" => "%{@fld61:*PARMVAL(event_user)}%{event_log},%{fld1},%{fld34} %{fld35},%{id},%{event_source},%{event_user},%{event_type},%{event_computer},%{category},%{fld2},User %{username} attempted to login but failed." }
				id => "message-USER_LOGIN_FAILED"
				add_field => {
				"ec_subject" => "User"
				"ec_activity" => "Logon"
				"ec_theme" => "Authentication"
				"ec_outcome" => "Failure"
					"[event][id]" => "USER_LOGIN_FAILED"
					"[rsa][message][id1]" => "USER_LOGIN_FAILED"
					"[event][categoryid]" => "1401030000"
					"[logstash][fullDateTimeString]" => "%{fld35}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "MMM dd H:m:s yyyy" ] }
			}
		}
		# MESSAGE USER_LOGIN
		# line in RSA: <@ec_subject:User><@ec_activity:Logon><@ec_theme:Authentication><@ec_outcome:Success><@fld61:*PARMVAL(event_user)><@:*SYSVAL($MSGID,$ID1)><@msg:*PARMVAL($MSG)><@event_time:*EVNTTIME($MSG,'%B %D %N:%U:%O %W',fld35)><event_log>,<fld1>,<fld34> <fld35>,<id>,<event_source>,<event_user>,<event_type>,<event_computer>,<category>,<fld2>,User <username> has successfully logged in.
		if ![logstash][messagefound] {
			dissect {
				mapping => { "message" => "%{@fld61:*PARMVAL(event_user)}%{event_log},%{fld1},%{fld34} %{fld35},%{id},%{event_source},%{event_user},%{event_type},%{event_computer},%{category},%{fld2},User %{username} has successfully logged in." }
				id => "message-USER_LOGIN"
				add_field => {
				"ec_subject" => "User"
				"ec_activity" => "Logon"
				"ec_theme" => "Authentication"
				"ec_outcome" => "Success"
					"[event][id]" => "USER_LOGIN"
					"[rsa][message][id1]" => "USER_LOGIN"
					"[event][categoryid]" => "1401060000"
					"[logstash][fullDateTimeString]" => "%{fld35}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "MMM dd H:m:s yyyy" ] }
			}
		}
		# MESSAGE 1000
		# line in RSA: <@msg:*PARMVAL($MSG)><@event_time:*EVNTTIME($MSG,'%B %D %N:%U:%O %W',fld35)><@fld61:*PARMVAL(event_user)><event_log>,<fld1>,<fld34> <fld35>,<id>,<event_source>,<event_user>,<event_type>,<event_computer>,<category>,<fld2>,User <username> <event_description>
		if ![logstash][messagefound] {
			dissect {
				mapping => { "message" => "%{@fld61:*PARMVAL(event_user)}%{event_log},%{fld1},%{fld34} %{fld35},%{id},%{event_source},%{event_user},%{event_type},%{event_computer},%{category},%{fld2},User %{username} %{event_description}" }
				id => "message-1000"
				add_field => {
					"[event][id]" => "1000"
					"[rsa][message][id1]" => "1000"
					"[event][categoryid]" => "1401000000"
					"[logstash][fullDateTimeString]" => "%{fld35}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "MMM dd H:m:s yyyy" ] }
			}
		}
	}
	# PARSER msgParserId3
	# line in RSA: <@msg:*PARMVAL($MSG)><event_time_string> CEF:0|Netwitness|Informer|<version>|<event_type>|<severity>|<fld81>externalId=<operation_id> proto=<fld14> art=<fld12>act=<action> rt=<fld4> deviceDirection=<fld5>shost=<shost>src=<saddr> spt=<sport> dhost=<dhost>dst=<daddr>dport=<dport> duser=<username> dproc=<fld7>fileType=<category> cs1=<fld8> cs2=<fld9> cs3=<content_type>cs4=<event_description> cn1=<fld10> cn2=<fld11> cn3=<fld13>
	else if [logstash][msgparser][id] == "msgParserId3" {
		dissect {
			mapping => { "message" => "%{event_time_string} CEF:0|Netwitness|Informer|%{version}|%{event_type}|%{severity}|%{fld81}externalId=%{operation_id} proto=%{fld14} art=%{fld12}act=%{action} rt=%{fld4} deviceDirection=%{fld5}shost=%{shost}src=%{saddr} spt=%{sport} dhost=%{dhost}dst=%{daddr}dport=%{dport} duser=%{username} dproc=%{fld7}fileType=%{category} cs1=%{fld8} cs2=%{fld9} cs3=%{content_type}cs4=%{event_description} cn1=%{fld10} cn2=%{fld11} cn3=%{fld13}" }
			id => "msgParserId3"
			add_field => {
				"[logstash][messagefound]" => true
			}
		}
	}
	# PARSER msgParserId4
	# line in RSA: <@msg:*PARMVAL($MSG)><event_time_string> CEF:0|Netwitness|Informer|<version>|<event_type>|<severity>|<fld81>externalId=<operation_id> proto=<fld14> act=<action> rt=<fld4> deviceDirection=<fld5>shost=<shost>src=<saddr> spt=<sport> dhost=<dhost>dst=<daddr>dport=<dport> duser=<username> dproc=<fld7>fileType=<category> cs1=<fld8> cs2=<fld9> cs3=<content_type>cs4=<event_description> cn1=<fld10> cn2=<fld11> cn3=<fld13>
	else if [logstash][msgparser][id] == "msgParserId4" {
		dissect {
			mapping => { "message" => "%{event_time_string} CEF:0|Netwitness|Informer|%{version}|%{event_type}|%{severity}|%{fld81}externalId=%{operation_id} proto=%{fld14} act=%{action} rt=%{fld4} deviceDirection=%{fld5}shost=%{shost}src=%{saddr} spt=%{sport} dhost=%{dhost}dst=%{daddr}dport=%{dport} duser=%{username} dproc=%{fld7}fileType=%{category} cs1=%{fld8} cs2=%{fld9} cs3=%{content_type}cs4=%{event_description} cn1=%{fld10} cn2=%{fld11} cn3=%{fld13}" }
			id => "msgParserId4"
			add_field => {
				"[logstash][messagefound]" => true
			}
		}
	}


################## END OF MESSAGES ##################

# End of the filter block
}


output {
#	if [logstash][headerfound] and [logstash][messagefound] {
#		elasticsearch {
#			hosts => ["https://elasticxxxxxx"]
#			index => "%{[observer][product]}-%{+YYYY.MM.dd}"
#			user => "logstash"
#			password => "abc"	# Better use keystore, cf https://www.elastic.co/guide/en/logstash/master/keystore.html
#			manage_template => true
#			template => "es-mapping-netwitnessmsg.json"
#			template_name => "_template"
#			template_overwrite => true
#		}
#	} else {
#		# using a file output for logs that were not parsed correctly
#		# should you chose to send it to elasticsearch, please read https://discuss.elastic.co/t/latency-with-2-elasticsearch-systems/170074/2
#		file { path => "failed_logs-%{[observer][product]}-%{+YYYY-MM-dd}" }
#	}
	stdout {
		codec => rubydebug
	}
}

# Config file generated by RSA2ELK, see https://github.com/blookot/rsa2elk 
# Author: Vincent Maury
# Check all Netwitness parsers: https://github.com/netwitness/nw-logparsers/tree/master/devices/ (license: Apache 2.0)
# Check this link to search for source configuration guides: https://rsa.jiveon.com/community/products/netwitness/integrations/event-sources

##########
# CAUTION: check the "path" in input and "dictionary_path" in filter, as well as the "template" path in the elasticsearch output or "path" in the file output
##########

input {
#	syslog {
#		port => 514
#	}
#	file {
#		path => "/var/log/example.log"
#		start_position => "beginning"
#		sincedb_path => "/dev/null"
#	}
	generator {
		count => 1
		message => "a log line to test out"
	}
#	kafka {
#		codec => "json"
#		bootstrap_servers => "192.168.30.13:9092"
#		topics => ["mytopic"]
#		security_protocol => "SSL"
#		ssl_key_password => "{ssl_password}"
#		ssl_keystore_location => "/{keystore-absolute-path}"
#		ssl_keystore_password => "{keystore_password}"
#		ssl_truststore_location => "/{truststore-absolute-path}"
#		ssl_truststore_password => "{truststore_password}"
#	}
}

# Renaming a couple of fields
filter {
	mutate {
		rename => {
			"message" => "[event][original]"
			"host" => "[logstash][host]"
		}
	}
}

# Setting the device name and group
filter {
	mutate {
		add_field => {
			"[observer][product]" => "dellswitch"
			"[observer][name]" => "Dell PowerSwitch"
			"[observer][type]" => "Switch"
		}
	}
}


# One single filter block for all headers and messages
filter {

################## HEADERS ##################

	# HEADER 0001
	# line in RSA: %<msgIdPart1>-<hlevel>-<msgIdPart2>: <!payload:msgIdPart1>
	if ![logstash][headerfound] {
		grok {
			match => { "[event][original]" => "^%(?<message>(?<msgIdPart1>[^\-]*)\-(?<hlevel>[^\-]*)\-(?<msgIdPart2>[^:]*):[\s]+(?<payload>.*))$" }
			id => "header-0001"
			add_field => {
				"[rsa][header][id]" => "0001"
				"[rsa][message][id2]" => "%{msgIdPart1}_%{msgIdPart2}"
				"[logstash][headerfound]" => true
			}
		}
	}
	# HEADER 0002
	# line in RSA: <month> <day> <time> <hostname> <messageid>[<hprocessid>]: <hfilename>(<hfld1>) <hfld2> %% <!payload:messageid>
	if ![logstash][headerfound] {
		grok {
			match => { "[event][original]" => "^(?<month>[^\s]*)[\s]+(?<day>[^\s]*)[\s]+(?<time>[^\s]*)[\s]+(?<hostname>[^\s]*)[\s]+(?<message>(?<messageid>[^\[]*)\[(?<hprocessid>[^\]]*)\]:[\s]+(?<hfilename>[^\(]*)\((?<hfld1>[^\)]*)\)[\s]+(?<hfld2>[^\s]*)[\s]+%%[\s]+(?<payload>.*))$" }
			id => "header-0002"
			add_field => {
				"[rsa][header][id]" => "0002"
				"[rsa][message][id2]" => "%{messageid}"
				"[logstash][headerfound]" => true
			}
		}
	}



################## MsgId2 to Parser ##################

	translate {
		field => "[rsa][message][id2]"
		destination => "[logstash][msgparser][id]"
		dictionary_path => "msgid2parserid-v20_dellswitchmsg.json"
		fallback => ""
		override => true
	}


################## MESSAGES ##################

	# PARSER msgParserId0
	# line in RSA:  <agent>-<severity>-<fld23>: Authentication failed for <network_service>, source - <saddr> 
	if [logstash][msgparser][id] == "msgParserId0" {
		dissect {
			mapping => { "message" => "%{agent}-%{severity}-%{fld23}: Authentication failed for %{network_service}, source - %{saddr}" }
			id => "msgParserId0"
			add_field => {
				"ec_theme" => "Authentication"
				"ec_outcome" => "Failure"
				"[logstash][messagefound]" => true
			}
		}
	}
	else if [logstash][msgparser][id] == "COPY_TRAP" {
		# MESSAGE 000002
		# line in RSA:  <service>-<severity>-<fld23>: The copy operation was completed <disposition>
		if ![logstash][messagefound] {
			dissect {
				mapping => { "message" => "%{service}-%{severity}-%{fld23}: The copy operation was completed %{disposition}" }
				id => "message-000002"
				add_field => {
					"[event][id]" => "000002"
					"[rsa][message][id1]" => "000002"
					"[event][categoryid]" => "1605000000"
					"[logstash][messagefound]" => true
				}
			}
		}
		# MESSAGE 000003
		# line in RSA:  <service>-<severity>-<fld23>: The copy operation has <disposition>
		if ![logstash][messagefound] {
			dissect {
				mapping => { "message" => "%{service}-%{severity}-%{fld23}: The copy operation has %{disposition}" }
				id => "message-000003"
				add_field => {
					"[event][id]" => "000003"
					"[rsa][message][id1]" => "000003"
					"[event][categoryid]" => "1601000000"
					"[logstash][messagefound]" => true
				}
			}
		}
	}
	# PARSER msgParserId3
	# line in RSA:  <service>-<severity>-<fld23>: Warm Startup
	else if [logstash][msgparser][id] == "msgParserId3" {
		dissect {
			mapping => { "message" => "%{service}-%{severity}-%{fld23}: Warm Startup" }
			id => "msgParserId3"
			add_field => {
				"[logstash][messagefound]" => true
			}
		}
	}
	# PARSER msgParserId4
	# line in RSA:  <service>-<severity>-Up:  <interface>
	else if [logstash][msgparser][id] == "msgParserId4" {
		dissect {
			mapping => { "message" => "%{service}-%{severity}-Up:  %{interface}" }
			id => "msgParserId4"
			add_field => {
				"[logstash][messagefound]" => true
			}
		}
	}
	# PARSER msgParserId5
	# line in RSA:  <service>-<severity>-Down:  <interface>
	else if [logstash][msgparser][id] == "msgParserId5" {
		dissect {
			mapping => { "message" => "%{service}-%{severity}-Down:  %{interface}" }
			id => "msgParserId5"
			add_field => {
				"[logstash][messagefound]" => true
			}
		}
	}
	# PARSER msgParserId6
	# line in RSA:  <agent>-<severity>-<fld23>: New <network_service> connection from <saddr>
	else if [logstash][msgparser][id] == "msgParserId6" {
		dissect {
			mapping => { "message" => "%{agent}-%{severity}-%{fld23}: New %{network_service} connection from %{saddr}" }
			id => "msgParserId6"
			add_field => {
				"[logstash][messagefound]" => true
			}
		}
	}
	# PARSER msgParserId7
	# line in RSA:  <agent>-<severity>-<fld23>: <network_service> connection from <saddr> terminated 
	else if [logstash][msgparser][id] == "msgParserId7" {
		dissect {
			mapping => { "message" => "%{agent}-%{severity}-%{fld23}: %{network_service} connection from %{saddr} terminated" }
			id => "msgParserId7"
			add_field => {
				"[logstash][messagefound]" => true
			}
		}
	}
	# PARSER msgParserId8
	# line in RSA:  <service>-<severity>-<fld23>: <interface>: <fld22> status <event_state>
	else if [logstash][msgparser][id] == "msgParserId8" {
		dissect {
			mapping => { "message" => "%{service}-%{severity}-%{fld23}: %{interface}: %{fld22} status %{event_state}" }
			id => "msgParserId8"
			add_field => {
				"[logstash][messagefound]" => true
			}
		}
	}
	# PARSER msgParserId9
	# line in RSA:  <service>-<severity>-<fld23>: An error message was received: <resultcode> <result>
	else if [logstash][msgparser][id] == "msgParserId9" {
		dissect {
			mapping => { "message" => "%{service}-%{severity}-%{fld23}: An error message was received: %{resultcode} %{result}" }
			id => "msgParserId9"
			add_field => {
				"[logstash][messagefound]" => true
			}
		}
	}
	else if [logstash][msgparser][id] == "TRAPMGR" {
		# MESSAGE TRAPMGR:01
		# line in RSA: <agent>[<process_id>]: <filename>(<fld2>) <fld3> %% An invalid user tried to login through CLI from <saddr>
		if ![logstash][messagefound] {
			dissect {
				mapping => { "message" => "%{agent}[%{process_id}]: %{filename}(%{fld2}) %{fld3} %% An invalid user tried to login through CLI from %{saddr}" }
				id => "message-TRAPMGR:01"
				add_field => {
				"event_description" => "An invalid user tried to login through CLI"
					"[event][id]" => "TRAPMGR:01"
					"[rsa][message][id1]" => "TRAPMGR:01"
					"[event][categoryid]" => "1301000000"
					"[logstash][fullDateTimeString]" => "%{month} %{day} %{time}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "MMM d HH:m:s" ] }
			}
		}
		# MESSAGE TRAPMGR:02
		# line in RSA: <agent>[<process_id>]: <filename>(<fld2>) <fld3> %% {Failed User Login with User ID|Failed User Login: Unit: <fld4> User ID}: <username>
		if ![logstash][messagefound] {
			grok {
				match => { "message" => "^(?<agent>[^\[]*)\[(?<process_id>[^\]]*)\]:[\s]+(?<filename>[^\(]*)\((?<fld2>[^\)]*)\)[\s]+(?<fld3>[^\s]*)[\s]+%%[\s]+(Failed[\s]+User[\s]+Login[\s]+with[\s]+User[\s]+ID|Failed[\s]+User[\s]+Login:[\s]+Unit:[\s]+(?<fld4>[^\s]*)[\s]+User[\s]+ID):[\s]+(?<username>.*)$" }
				id => "message-TRAPMGR:02"
				add_field => {
				"ec_subject" => "User"
				"ec_activity" => "Logon"
				"ec_theme" => "Authentication"
				"ec_outcome" => "Failure"
					"[event][id]" => "TRAPMGR:02"
					"[rsa][message][id1]" => "TRAPMGR:02"
					"[event][categoryid]" => "1401030000"
					"[logstash][fullDateTimeString]" => "%{month} %{day} %{time}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "MMM d HH:m:s" ] }
			}
		}
		# MESSAGE TRAPMGR
		# line in RSA: <agent>[<process_id>]: <filename>(<fld2>) <fld3> %% <info>
		if ![logstash][messagefound] {
			dissect {
				mapping => { "message" => "%{agent}[%{process_id}]: %{filename}(%{fld2}) %{fld3} %% %{info}" }
				id => "message-TRAPMGR"
				add_field => {
					"[event][id]" => "TRAPMGR"
					"[rsa][message][id1]" => "TRAPMGR"
					"[event][categoryid]" => "1605000000"
					"[logstash][fullDateTimeString]" => "%{month} %{day} %{time}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "MMM d HH:m:s" ] }
			}
		}
	}
	# PARSER msgParserId12
	# line in RSA: <agent>[<process_id>]: <filename>(<fld2>) <fld3> %% <info>
	else if [logstash][msgparser][id] == "msgParserId12" {
		dissect {
			mapping => { "message" => "%{agent}[%{process_id}]: %{filename}(%{fld2}) %{fld3} %% %{info}" }
			id => "msgParserId12"
			add_field => {
				"[logstash][fullDateTimeString]" => "%{month} %{day} %{time}"
				"[logstash][messagefound]" => true
			}
		}
		if [logstash][fullDateTimeString] {
			date { match => [ "[logstash][fullDateTimeString]", "MMM d HH:m:s" ] }
		}
	}
	# PARSER msgParserId13
	# line in RSA: <agent>[<process_id>]: <filename>(<fld2>) <fld3> %% User <username> Failed to login because of authentication failures
	else if [logstash][msgparser][id] == "msgParserId13" {
		dissect {
			mapping => { "message" => "%{agent}[%{process_id}]: %{filename}(%{fld2}) %{fld3} %% User %{username} Failed to login because of authentication failures" }
			id => "msgParserId13"
			add_field => {
				"ec_subject" => "User"
				"ec_activity" => "Logon"
				"ec_theme" => "Authentication"
				"ec_outcome" => "Failure"
				"[logstash][fullDateTimeString]" => "%{month} %{day} %{time}"
				"[logstash][messagefound]" => true
			}
		}
		if [logstash][fullDateTimeString] {
			date { match => [ "[logstash][fullDateTimeString]", "MMM d HH:m:s" ] }
		}
	}
	else if [logstash][msgparser][id] == "CLI_WEB" {
		# MESSAGE CLI_WEB:01
		# line in RSA: <agent>[<process_id>]: <filename>(<fld2>) <fld3> %% [CLI:<web_method> / <protocol>/<version>:<saddr>] User login authentication failed
		if ![logstash][messagefound] {
			dissect {
				mapping => { "message" => "%{agent}[%{process_id}]: %{filename}(%{fld2}) %{fld3} %% [CLI:%{web_method} / %{protocol}/%{version}:%{saddr}] User login authentication failed" }
				id => "message-CLI_WEB:01"
				add_field => {
				"ec_subject" => "User"
				"ec_activity" => "Logon"
				"ec_theme" => "Authentication"
				"ec_outcome" => "Failure"
					"[event][id]" => "CLI_WEB:01"
					"[rsa][message][id1]" => "CLI_WEB:01"
					"[event][categoryid]" => "1401030000"
					"[logstash][fullDateTimeString]" => "%{month} %{day} %{time}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "MMM d HH:m:s" ] }
			}
		}
		# MESSAGE CLI_WEB
		# line in RSA: <agent>[<process_id>]: <filename>(<fld2>) <fld3> %% <info>
		if ![logstash][messagefound] {
			dissect {
				mapping => { "message" => "%{agent}[%{process_id}]: %{filename}(%{fld2}) %{fld3} %% %{info}" }
				id => "message-CLI_WEB"
				add_field => {
					"[event][id]" => "CLI_WEB"
					"[rsa][message][id1]" => "CLI_WEB"
					"[event][categoryid]" => "1605000000"
					"[logstash][fullDateTimeString]" => "%{month} %{day} %{time}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "MMM d HH:m:s" ] }
			}
		}
	}


################## END OF MESSAGES ##################

# End of the filter block
}

# Enrich events using VALUEMAP
filter {
	translate {
		field => "[severity]"
		destination => "[severity]"
		dictionary => {
			"W" => "Warning"
			"I" => "Informational"
			"E" => "Error"
		}
		fallback => ""
		override => true
	}
}


output {
#	if [logstash][headerfound] and [logstash][messagefound] {
#		elasticsearch {
#			hosts => ["https://elasticxxxxxx"]
#			index => "%{[observer][product]}-%{+YYYY.MM.dd}"
#			user => "logstash"
#			password => "abc"	# Better use keystore, cf https://www.elastic.co/guide/en/logstash/master/keystore.html
#			manage_template => true
#			template => "es-mapping-v20_dellswitchmsg.json"
#			template_name => "dellswitch_template"
#			template_overwrite => true
#		}
#	} else {
#		# using a file output for logs that were not parsed correctly
#		# should you chose to send it to elasticsearch, please read https://discuss.elastic.co/t/latency-with-2-elasticsearch-systems/170074/2
#		file { path => "failed_logs-%{[observer][product]}-%{+YYYY-MM-dd}" }
#	}
	stdout {
		codec => rubydebug
	}
}

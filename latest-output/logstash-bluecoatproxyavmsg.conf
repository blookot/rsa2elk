# Config file generated by RSA2ELK, see https://github.com/blookot/rsa2elk 
# Author: Vincent Maury
# Check all Netwitness parsers: https://github.com/netwitness/nw-logparsers/tree/master/devices/ (license: Apache 2.0)
# Check this link to search for source configuration guides: https://rsa.jiveon.com/community/products/netwitness/integrations/event-sources

##########
# CAUTION: check the "path" in input and "dictionary_path" in filter, as well as the "template" path in the elasticsearch output or "path" in the file output
##########

input {
#	syslog {
#		port => 514
#	}
#	file {
#		path => "/var/log/example.log"
#		start_position => "beginning"
#		sincedb_path => "/dev/null"
#	}
	generator {
		count => 1
		message => "a log line to test out"
	}
#	kafka {
#		codec => "json"
#		bootstrap_servers => "192.168.30.13:9092"
#		topics => ["mytopic"]
#		security_protocol => "SSL"
#		ssl_key_password => "{ssl_password}"
#		ssl_keystore_location => "/{keystore-absolute-path}"
#		ssl_keystore_password => "{keystore_password}"
#		ssl_truststore_location => "/{truststore-absolute-path}"
#		ssl_truststore_password => "{truststore_password}"
#	}
}

# Renaming a couple of fields
filter {
	mutate {
		rename => {
			"message" => "[event][original]"
			"host" => "[logstash][host]"
		}
	}
}

# Setting the device name and group
filter {
	mutate {
		add_field => {
			"[observer][product]" => "bluecoatproxyav"
			"[observer][name]" => "Blue Coat ProxyAV"
			"[observer][type]" => "Anti Virus"
		}
	}
}


# One single filter block for all headers and messages
filter {

################## HEADERS ##################

	# HEADER 0001
	# line in RSA: %PROXYAV <messageid>: <!payload>
	if ![logstash][headerfound] {
		dissect {
			mapping => { "[event][original]" => "%PROXYAV %{messageid}: %{message}" }
			id => "header-0001"
			add_field => {
				"[rsa][header][id]" => "0001"
				"[rsa][message][id2]" => "%{messageid}"
				"[logstash][headerfound]" => true
			}
		}
	}
	# HEADER 0002
	# line in RSA: %PROXYAV <messageid> ^<!payload>
	if ![logstash][headerfound] {
		dissect {
			mapping => { "[event][original]" => "%PROXYAV %{messageid} ^%{message}" }
			id => "header-0002"
			add_field => {
				"[rsa][header][id]" => "0002"
				"[rsa][message][id2]" => "%{messageid}"
				"[logstash][headerfound]" => true
			}
		}
	}
	# HEADER 0008
	# line in RSA: <hfld1> <hfld2> <hfld3> <hfld4> <hfld5> <hfld6> <messageid>, <!payload:messageid>
	if ![logstash][headerfound] {
		grok {
			match => { "[event][original]" => "^(?<hfld1>[^\s]*)[\s]+(?<hfld2>[^\s]*)[\s]+(?<hfld3>[^\s]*)[\s]+(?<hfld4>[^\s]*)[\s]+(?<hfld5>[^\s]*)[\s]+(?<hfld6>[^\s]*)[\s]+(?<message>(?<messageid>[^,]*),[\s]+(?<payload>.*))$" }
			id => "header-0008"
			add_field => {
				"[rsa][header][id]" => "0008"
				"[rsa][message][id2]" => "%{messageid}"
				"[logstash][headerfound]" => true
			}
		}
	}
	# HEADER 0006
	# line in RSA: <hfld1> <hfld2> <hfld3> <hfld4> <hfld5> <hfld6> <msgIdPart1> <msgIdPart2>, <!payload:msgIdPart1>
	if ![logstash][headerfound] {
		grok {
			match => { "[event][original]" => "^(?<hfld1>[^\s]*)[\s]+(?<hfld2>[^\s]*)[\s]+(?<hfld3>[^\s]*)[\s]+(?<hfld4>[^\s]*)[\s]+(?<hfld5>[^\s]*)[\s]+(?<hfld6>[^\s]*)[\s]+(?<message>(?<msgIdPart1>[^\s]*)[\s]+(?<msgIdPart2>[^,]*),[\s]+(?<payload>.*))$" }
			id => "header-0006"
			add_field => {
				"[rsa][header][id]" => "0006"
				"[rsa][message][id2]" => "%{msgIdPart1}_%{msgIdPart2}"
				"[logstash][headerfound]" => true
			}
		}
	}
	# HEADER 0009
	# line in RSA: <hfld1> <hfld2>T<hfld3>-<hfld4> <hfld5> <hfld6> <hfld7> <hfld8> <messageid> <!payload:messageid>
	if ![logstash][headerfound] {
		grok {
			match => { "[event][original]" => "^(?<hfld1>[^\s]*)[\s]+(?<hfld2>[^T]*)T(?<hfld3>[^\-]*)\-(?<hfld4>[^\s]*)[\s]+(?<hfld5>[^\s]*)[\s]+(?<hfld6>[^\s]*)[\s]+(?<hfld7>[^\s]*)[\s]+(?<hfld8>[^\s]*)[\s]+(?<message>(?<messageid>[^\s]*)[\s]+(?<payload>.*))$" }
			id => "header-0009"
			add_field => {
				"[rsa][header][id]" => "0009"
				"[rsa][message][id2]" => "%{messageid}"
				"[logstash][headerfound]" => true
			}
		}
	}
	# HEADER 0004
	# line in RSA: <messageid>, <!payload:messageid>
	if ![logstash][headerfound] {
		grok {
			match => { "[event][original]" => "^(?<message>(?<messageid>[^,]*),[\s]+(?<payload>.*))$" }
			id => "header-0004"
			add_field => {
				"[rsa][header][id]" => "0004"
				"[rsa][message][id2]" => "%{messageid}"
				"[logstash][headerfound]" => true
			}
		}
	}
	# HEADER 0005
	# line in RSA: <msgIdPart1> <msgIdPart2>, <!payload:msgIdPart1>
	if ![logstash][headerfound] {
		grok {
			match => { "[event][original]" => "^(?<message>(?<msgIdPart1>[^\s]*)[\s]+(?<msgIdPart2>[^,]*),[\s]+(?<payload>.*))$" }
			id => "header-0005"
			add_field => {
				"[rsa][header][id]" => "0005"
				"[rsa][message][id2]" => "%{msgIdPart1}_%{msgIdPart2}"
				"[logstash][headerfound]" => true
			}
		}
	}
	# HEADER 0007
	# line in RSA: %ProxyAV <messageid> <!payload:messageid>
	if ![logstash][headerfound] {
		grok {
			match => { "[event][original]" => "^%ProxyAV[\s]+(?<message>(?<messageid>[^\s]*)[\s]+(?<payload>.*))$" }
			id => "header-0007"
			add_field => {
				"[rsa][header][id]" => "0007"
				"[rsa][message][id2]" => "%{messageid}"
				"[logstash][headerfound]" => true
			}
		}
	}



################## MsgId2 to Parser ##################

	translate {
		field => "[rsa][message][id2]"
		destination => "[logstash][msgparser][id]"
		dictionary_path => "msgid2parserid-bluecoatproxyavmsg.json"
		fallback => ""
		override => true
	}


################## MESSAGES ##################

	# PARSER msgParserId0
	# line in RSA:  <virusname>; File:<filename>; Sub File: <fld1>; Vendor: <agent>; Engine error code: <fld3>; Engine version: <component_version>; Pattern version: <fld4>; Pattern date: <fld5>^<fld6>^<url>
	if [logstash][msgparser][id] == "msgParserId0" {
		dissect {
			mapping => { "message" => "%{virusname}; File:%{filename}; Sub File: %{fld1}; Vendor: %{agent}; Engine error code: %{fld3}; Engine version: %{component_version}; Pattern version: %{fld4}; Pattern date: %{fld5}^%{fld6}^%{url}" }
			id => "msgParserId0"
			add_field => {
				"[logstash][fullDateTimeString]" => "%{fld5}"
				"[logstash][messagefound]" => true
			}
		}
		if [logstash][fullDateTimeString] {
			date { match => [ "[logstash][fullDateTimeString]", "yyyy.M.d HH:m:s" ] }
		}
	}
	else if [logstash][msgparser][id] == "antivirus_load_failure" {
		# MESSAGE antivirus_load_failure
		# line in RSA:  <event_description>; File:<filename>; Sub File: <fld1>; Vendor: <agent>; Engine error code: <fld3>; Engine version: <component_version>; Pattern version: <fld4>; Pattern date: unknown^<url>
		if ![logstash][messagefound] {
			dissect {
				mapping => { "message" => "%{event_description}; File:%{filename}; Sub File: %{fld1}; Vendor: %{agent}; Engine error code: %{fld3}; Engine version: %{component_version}; Pattern version: %{fld4}; Pattern date: unknown^%{url}" }
				id => "message-antivirus_load_failure"
				add_field => {
					"[event][id]" => "antivirus_load_failure"
					"[rsa][message][id1]" => "antivirus_load_failure"
					"[event][categoryid]" => "1603040000"
					"[logstash][messagefound]" => true
				}
			}
		}
		# MESSAGE antivirus_load_failure:01
		# line in RSA:  <event_description>; File:<filename>; Sub File: <fld1>; Vendor: <agent>; Engine error code: <fld3>; Engine version: <component_version>; Pattern version: <fld4>; Pattern date: <fld5>^<url>
		if ![logstash][messagefound] {
			dissect {
				mapping => { "message" => "%{event_description}; File:%{filename}; Sub File: %{fld1}; Vendor: %{agent}; Engine error code: %{fld3}; Engine version: %{component_version}; Pattern version: %{fld4}; Pattern date: %{fld5}^%{url}" }
				id => "message-antivirus_load_failure:01"
				add_field => {
					"[event][id]" => "antivirus_load_failure:01"
					"[rsa][message][id1]" => "antivirus_load_failure:01"
					"[event][categoryid]" => "1603040000"
					"[logstash][fullDateTimeString]" => "%{fld5}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "yyyy.M.d HH:m:s" ] }
			}
		}
	}
	# PARSER msgParserId2
	# line in RSA:  <event_description>; File:<filename>; Sub File: <fld1>; Vendor: <agent>; Engine error code: <fld3>; Engine version: <component_version>; Pattern version: <fld4>; Pattern date: <fld5>^<url>
	else if [logstash][msgparser][id] == "msgParserId2" {
		dissect {
			mapping => { "message" => "%{event_description}; File:%{filename}; Sub File: %{fld1}; Vendor: %{agent}; Engine error code: %{fld3}; Engine version: %{component_version}; Pattern version: %{fld4}; Pattern date: %{fld5}^%{url}" }
			id => "msgParserId2"
			add_field => {
				"[logstash][fullDateTimeString]" => "%{fld5}"
				"[logstash][messagefound]" => true
			}
		}
		if [logstash][fullDateTimeString] {
			date { match => [ "[logstash][fullDateTimeString]", "yyyy.M.d HH:m:s" ] }
		}
	}
	# PARSER msgParserId3
	# line in RSA:  <agent>^<component_version>^<fld13>
	else if [logstash][msgparser][id] == "msgParserId3" {
		dissect {
			mapping => { "message" => "%{agent}^%{component_version}^%{fld13}" }
			id => "msgParserId3"
			add_field => {
				"[logstash][messagefound]" => true
			}
		}
	}
	# PARSER msgParserId4
	# line in RSA: <event_source> <event_description>
	else if [logstash][msgparser][id] == "msgParserId4" {
		dissect {
			mapping => { "message" => "%{event_source} %{event_description}" }
			id => "msgParserId4"
			add_field => {
				"[logstash][messagefound]" => true
			}
		}
	}
	# PARSER msgParserId5
	# line in RSA:  <agent>^<fld13>
	else if [logstash][msgparser][id] == "msgParserId5" {
		dissect {
			mapping => { "message" => "%{agent}^%{fld13}" }
			id => "msgParserId5"
			add_field => {
				"[logstash][messagefound]" => true
			}
		}
	}
	# PARSER msgParserId6
	# line in RSA:  <protocol>, <sbytes>, <fld1>, <fld2>, <fld3>, <processing_time>, <shost>, <saddr>, <username>, <dhost>, <daddr>, <dport>, <service>, <rbytes>, <web_method>, <content_type>, <resultcode>, <user_agent>, <url>, { <web_root>, <web_query> | <web_query> }
	else if [logstash][msgparser][id] == "msgParserId6" {
		grok {
			match => { "message" => "^[\s]*(?<protocol>[^,]*),[\s]+(?<sbytes>[^,]*),[\s]+(?<fld1>[^,]*),[\s]+(?<fld2>[^,]*),[\s]+(?<fld3>[^,]*),[\s]+(?<processing_time>[^,]*),[\s]+(?<shost>[^,]*),[\s]+(?<saddr>[^,]*),[\s]+(?<username>[^,]*),[\s]+(?<dhost>[^,]*),[\s]+(?<daddr>[^,]*),[\s]+(?<dport>[^,]*),[\s]+(?<service>[^,]*),[\s]+(?<rbytes>[^,]*),[\s]+(?<web_method>[^,]*),[\s]+(?<content_type>[^,]*),[\s]+(?<resultcode>[^,]*),[\s]+(?<user_agent>[^,]*),[\s]+(?<url>[^,]*),[\s]+([\s]*(?<web_root>[^,]*),[\s]+(?<web_query>[^\s]*)[\s]+|[\s]*(?<web_query>[^\s]*)[\s]+)$" }
			id => "msgParserId6"
			add_field => {
				"[logstash][fullDateTimeString]" => "%{fld2} %{fld3}"
				"[logstash][messagefound]" => true
			}
		}
		if [logstash][fullDateTimeString] {
			date { match => [ "[logstash][fullDateTimeString]", "yyyy-M-d HH:m:s" ] }
		}
	}
	else if [logstash][msgparser][id] == "User" {
		# MESSAGE User:01
		# line in RSA:  User "<username>" changed <change_attribute> from <change_old> to <change_new> using <network_service>
		if ![logstash][messagefound] {
			dissect {
				mapping => { "message" => "User \"%{username}\" changed %{change_attribute} from %{change_old} to %{change_new} using %{network_service}" }
				id => "message-User:01"
				add_field => {
					"[event][id]" => "User:01"
					"[rsa][message][id1]" => "User:01"
					"[event][categoryid]" => "1701000000"
					"[logstash][fullDateTimeString]" => "%{hfld2} %{hfld3}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "yyyy-M-d HH:m:s" ] }
			}
		}
		# MESSAGE User:02
		# line in RSA:  User "<username>" changed <change_attribute> to <change_new> using <network_service>
		if ![logstash][messagefound] {
			dissect {
				mapping => { "message" => "User \"%{username}\" changed %{change_attribute} to %{change_new} using %{network_service}" }
				id => "message-User:02"
				add_field => {
					"[event][id]" => "User:02"
					"[rsa][message][id1]" => "User:02"
					"[event][categoryid]" => "1701000000"
					"[logstash][fullDateTimeString]" => "%{hfld2} %{hfld3}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "yyyy-M-d HH:m:s" ] }
			}
		}
	}
	# PARSER msgParserId9
	# line in RSA:  <protocol>, <sbytes>, <fld1>, <fld2>, <fld3>, <processing_time>, <shost>, <saddr>, <username>, <dhost>, <daddr>, <dport>, <service>, <rbytes>, <web_method>, <content_type>, <resultcode>, <user_agent>, <url>, <web_root>, <web_query>
	else if [logstash][msgparser][id] == "msgParserId9" {
		dissect {
			mapping => { "message" => "%{protocol}, %{sbytes}, %{fld1}, %{fld2}, %{fld3}, %{processing_time}, %{shost}, %{saddr}, %{username}, %{dhost}, %{daddr}, %{dport}, %{service}, %{rbytes}, %{web_method}, %{content_type}, %{resultcode}, %{user_agent}, %{url}, %{web_root}, %{web_query}" }
			id => "msgParserId9"
			add_field => {
				"[logstash][fullDateTimeString]" => "%{fld2} %{fld3}"
				"[logstash][messagefound]" => true
			}
		}
		if [logstash][fullDateTimeString] {
			date { match => [ "[logstash][fullDateTimeString]", "yyyy-M-d HH:m:s" ] }
		}
	}
	else if [logstash][msgparser][id] == "File" {
		# MESSAGE File:01
		# line in RSA:  File decompression/decode error; File:<filename>; Sub File: <fld1>; Vendor: <agent>; Engine error code: <fld3>; Engine version: <component_version>; Pattern version: <fld4>; Pattern date: <fld5>;<fld6>;<url>
		if ![logstash][messagefound] {
			dissect {
				mapping => { "message" => "File decompression/decode error; File:%{filename}; Sub File: %{fld1}; Vendor: %{agent}; Engine error code: %{fld3}; Engine version: %{component_version}; Pattern version: %{fld4}; Pattern date: %{fld5};%{fld6};%{url}" }
				id => "message-File:01"
				add_field => {
					"[event][id]" => "File:01"
					"[rsa][message][id1]" => "File:01"
					"[event][categoryid]" => "1204000000"
					"[logstash][fullDateTimeString]" => "%{fld5}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "yyyy.M.d HH:m:s" ] }
			}
		}
		# MESSAGE File
		# line in RSA:  File is password protected; File:<filename>; Sub File: <fld1>; Vendor: <agent>; Engine error code: <fld3>; Engine version: <component_version>; Pattern version: <fld4>; Pattern date: <fld5>;<fld6>;<url>
		if ![logstash][messagefound] {
			dissect {
				mapping => { "message" => "File is password protected; File:%{filename}; Sub File: %{fld1}; Vendor: %{agent}; Engine error code: %{fld3}; Engine version: %{component_version}; Pattern version: %{fld4}; Pattern date: %{fld5};%{fld6};%{url}" }
				id => "message-File"
				add_field => {
					"[event][id]" => "File"
					"[rsa][message][id1]" => "File"
					"[event][categoryid]" => "1204000000"
					"[logstash][fullDateTimeString]" => "%{fld5}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "yyyy.M.d HH:m:s" ] }
			}
		}
	}
	# PARSER msgParserId12
	# line in RSA:  Antivirus license expired; File:<filename>; Sub File: <fld1>; Vendor: <agent> Engine error code: <fld3>; Engine version: <component_version>; Pattern version: <fld4>; Pattern date: <fld5>;<fld6>
	else if [logstash][msgparser][id] == "msgParserId12" {
		dissect {
			mapping => { "message" => "Antivirus license expired; File:%{filename}; Sub File: %{fld1}; Vendor: %{agent} Engine error code: %{fld3}; Engine version: %{component_version}; Pattern version: %{fld4}; Pattern date: %{fld5};%{fld6}" }
			id => "msgParserId12"
			add_field => {
				"[logstash][fullDateTimeString]" => "%{fld5}"
				"[logstash][messagefound]" => true
			}
		}
		if [logstash][fullDateTimeString] {
			date { match => [ "[logstash][fullDateTimeString]", "yyyy.M.d HH:m:s" ] }
		}
	}


################## END OF MESSAGES ##################

# End of the filter block
}


output {
#	if [logstash][headerfound] and [logstash][messagefound] {
#		elasticsearch {
#			hosts => ["https://elasticxxxxxx"]
#			index => "%{[observer][product]}-%{+YYYY.MM.dd}"
#			user => "logstash"
#			password => "abc"	# Better use keystore, cf https://www.elastic.co/guide/en/logstash/master/keystore.html
#			manage_template => true
#			template => "es-mapping-bluecoatproxyavmsg.json"
#			template_name => "bluecoatproxyav_template"
#			template_overwrite => true
#		}
#	} else {
#		# using a file output for logs that were not parsed correctly
#		# should you chose to send it to elasticsearch, please read https://discuss.elastic.co/t/latency-with-2-elasticsearch-systems/170074/2
#		file { path => "failed_logs-%{[observer][product]}-%{+YYYY-MM-dd}" }
#	}
	stdout {
		codec => rubydebug
	}
}

# Config file generated by RSA2ELK, see https://github.com/blookot/rsa2elk 
# Author: Vincent Maury
# Check all Netwitness parsers: https://github.com/netwitness/nw-logparsers/tree/master/devices/ (license: Apache 2.0)
# Check this link to search for source configuration guides: https://rsa.jiveon.com/community/products/netwitness/integrations/event-sources

##########
# CAUTION: check the "path" in input and "dictionary_path" in filter, as well as the "template" path in the elasticsearch output or "path" in the file output
##########

input {
#	syslog {
#		port => 514
#	}
#	file {
#		path => "/var/log/example.log"
#		start_position => "beginning"
#		sincedb_path => "/dev/null"
#	}
	generator {
		count => 1
		message => "a log line to test out"
	}
#	kafka {
#		codec => "json"
#		bootstrap_servers => "192.168.30.13:9092"
#		topics => ["mytopic"]
#		security_protocol => "SSL"
#		ssl_key_password => "{ssl_password}"
#		ssl_keystore_location => "/{keystore-absolute-path}"
#		ssl_keystore_password => "{keystore_password}"
#		ssl_truststore_location => "/{truststore-absolute-path}"
#		ssl_truststore_password => "{truststore_password}"
#	}
}

# Renaming a couple of fields
filter {
	mutate {
		rename => {
			"message" => "[event][original]"
			"host" => "[logstash][host]"
		}
	}
}

# Setting the device name and group
filter {
	mutate {
		add_field => {
			"[observer][product]" => "sonicwallgms"
			"[observer][name]" => "SonicWALL GMS"
			"[observer][type]" => "Configuration Management"
		}
	}
}


# One single filter block for all headers and messages
filter {

################## HEADERS ##################

	# HEADER 0001
	# line in RSA: %SONICWALLGMS: <messageid>^^<hyear>-<hmonth>-<hday> <htime>^^<!payload:messageid>
	if ![logstash][headerfound] {
		grok {
			match => { "[event][original]" => "^%SONICWALLGMS:[\s]+(?<message>(?<messageid>[^\^]*)\^\^(?<hyear>[^\-]*)\-(?<hmonth>[^\-]*)\-(?<hday>[^\s]*)[\s]+(?<htime>[^\^]*)\^\^(?<payload>.*))$" }
			id => "header-0001"
			add_field => {
				"[rsa][header][id]" => "0001"
				"[rsa][message][id2]" => "%{messageid}"
				"[logstash][headerfound]" => true
			}
		}
	}



################## MsgId2 to Parser ##################

	translate {
		field => "[rsa][message][id2]"
		destination => "[logstash][msgparser][id]"
		dictionary_path => "msgid2parserid-v20_sonicwallgmsmsg.json"
		fallback => ""
		override => true
	}


################## MESSAGES ##################

	if [logstash][msgparser][id] == "SW_AUDIT_LOG" {
		# MESSAGE SW_AUDIT_LOG:01
		# line in RSA: SW_AUDIT_LOG^^<fld1>-<fld2>-<fld3> <fld4>:<fld5>:<fld6>^^<fld7>^^<username>^^<severity>^^<hostip>^^{<fld14>-<fld15>-<fld16> <fld17>:<fld18>:<fld19>|(null)}^^<fld20>^^<domain_id>^^Unsuccessful login attempt into the system by user: <fld8>
		if ![logstash][messagefound] {
			grok {
				match => { "message" => "^SW_AUDIT_LOG\^\^(?<fld1>[^\-]*)\-(?<fld2>[^\-]*)\-(?<fld3>[^\s]*)[\s]+(?<fld4>[^:]*):(?<fld5>[^:]*):(?<fld6>[^\^]*)\^\^(?<fld7>[^\^]*)\^\^(?<username>[^\^]*)\^\^(?<severity>[^\^]*)\^\^(?<hostip>[^\^]*)\^\^((?<fld14>[^\-]*)\-(?<fld15>[^\-]*)\-(?<fld16>[^\s]*)[\s]+(?<fld17>[^:]*):(?<fld18>[^:]*):(?<fld19>[^\^]*)|\(null\))\^\^(?<fld20>[^\^]*)\^\^(?<domain_id>[^\^]*)\^\^Unsuccessful[\s]+login[\s]+attempt[\s]+into[\s]+the[\s]+system[\s]+by[\s]+user:[\s]+(?<fld8>.*)$" }
				id => "message-SW_AUDIT_LOG:01"
				add_field => {
				"ec_subject" => "User"
				"ec_activity" => "Logon"
				"ec_outcome" => "Failure"
					"[event][id]" => "SW_AUDIT_LOG:01"
					"[rsa][message][id1]" => "SW_AUDIT_LOG:01"
					"[event][categoryid]" => "1401030000"
					"[logstash][fullDateTimeString]" => "%{fld1} %{fld2} %{fld3} %{fld4} %{fld5} %{fld6}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "yyyy M d H m s" ] }
			}
		}
		# MESSAGE SW_AUDIT_LOG:02
		# line in RSA: SW_AUDIT_LOG^^<fld1>-<fld2>-<fld3> <fld4>:<fld5>:<fld6>^^<fld7>^^<username>^^<severity>^^<hostip>^^{<fld14>-<fld15>-<fld16> <fld17>:<fld18>:<fld19>|(null)}^^<fld20>^^<domain_id>^^Successful login into the system by user: <fld8>
		if ![logstash][messagefound] {
			grok {
				match => { "message" => "^SW_AUDIT_LOG\^\^(?<fld1>[^\-]*)\-(?<fld2>[^\-]*)\-(?<fld3>[^\s]*)[\s]+(?<fld4>[^:]*):(?<fld5>[^:]*):(?<fld6>[^\^]*)\^\^(?<fld7>[^\^]*)\^\^(?<username>[^\^]*)\^\^(?<severity>[^\^]*)\^\^(?<hostip>[^\^]*)\^\^((?<fld14>[^\-]*)\-(?<fld15>[^\-]*)\-(?<fld16>[^\s]*)[\s]+(?<fld17>[^:]*):(?<fld18>[^:]*):(?<fld19>[^\^]*)|\(null\))\^\^(?<fld20>[^\^]*)\^\^(?<domain_id>[^\^]*)\^\^Successful[\s]+login[\s]+into[\s]+the[\s]+system[\s]+by[\s]+user:[\s]+(?<fld8>.*)$" }
				id => "message-SW_AUDIT_LOG:02"
				add_field => {
				"ec_subject" => "User"
				"ec_activity" => "Logon"
				"ec_outcome" => "Success"
					"[event][id]" => "SW_AUDIT_LOG:02"
					"[rsa][message][id1]" => "SW_AUDIT_LOG:02"
					"[event][categoryid]" => "1302000000"
					"[logstash][fullDateTimeString]" => "%{fld1} %{fld2} %{fld3} %{fld4} %{fld5} %{fld6}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "yyyy M d H m s" ] }
			}
		}
		# MESSAGE SW_AUDIT_LOG:03
		# line in RSA: SW_AUDIT_LOG^^<fld1>-<fld2>-<fld3> <fld4>:<fld5>:<fld6>^^<fld7>^^<username>^^<severity>^^<hostip>^^{<fld14>-<fld15>-<fld16> <fld17>:<fld18>:<fld19>|(null)}^^<fld20>^^<domain_id>^^Acquire Failed: Login error: <result>.
		if ![logstash][messagefound] {
			grok {
				match => { "message" => "^SW_AUDIT_LOG\^\^(?<fld1>[^\-]*)\-(?<fld2>[^\-]*)\-(?<fld3>[^\s]*)[\s]+(?<fld4>[^:]*):(?<fld5>[^:]*):(?<fld6>[^\^]*)\^\^(?<fld7>[^\^]*)\^\^(?<username>[^\^]*)\^\^(?<severity>[^\^]*)\^\^(?<hostip>[^\^]*)\^\^((?<fld14>[^\-]*)\-(?<fld15>[^\-]*)\-(?<fld16>[^\s]*)[\s]+(?<fld17>[^:]*):(?<fld18>[^:]*):(?<fld19>[^\^]*)|\(null\))\^\^(?<fld20>[^\^]*)\^\^(?<domain_id>[^\^]*)\^\^Acquire[\s]+Failed:[\s]+Login[\s]+error:[\s]+(?<result>[^\.]*)\.$" }
				id => "message-SW_AUDIT_LOG:03"
				add_field => {
				"ec_subject" => "User"
				"ec_activity" => "Logon"
				"ec_outcome" => "Error"
					"[event][id]" => "SW_AUDIT_LOG:03"
					"[rsa][message][id1]" => "SW_AUDIT_LOG:03"
					"[event][categoryid]" => "1301020000"
					"[logstash][fullDateTimeString]" => "%{fld1} %{fld2} %{fld3} %{fld4} %{fld5} %{fld6}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "yyyy M d H m s" ] }
			}
		}
		# MESSAGE SW_AUDIT_LOG:04
		# line in RSA: SW_AUDIT_LOG^^<fld1>-<fld2>-<fld3> <fld4>:<fld5>:<fld6>^^<fld7>^^<username>^^<severity>^^<hostip>^^{<fld14>-<fld15>-<fld16> <fld17>:<fld18>:<fld19>|(null)}^^<fld20>^^<domain_id>^^<service> service has been <fld21>
		if ![logstash][messagefound] {
			grok {
				match => { "message" => "^SW_AUDIT_LOG\^\^(?<fld1>[^\-]*)\-(?<fld2>[^\-]*)\-(?<fld3>[^\s]*)[\s]+(?<fld4>[^:]*):(?<fld5>[^:]*):(?<fld6>[^\^]*)\^\^(?<fld7>[^\^]*)\^\^(?<username>[^\^]*)\^\^(?<severity>[^\^]*)\^\^(?<hostip>[^\^]*)\^\^((?<fld14>[^\-]*)\-(?<fld15>[^\-]*)\-(?<fld16>[^\s]*)[\s]+(?<fld17>[^:]*):(?<fld18>[^:]*):(?<fld19>[^\^]*)|\(null\))\^\^(?<fld20>[^\^]*)\^\^(?<domain_id>[^\^]*)\^\^(?<service>[^\s]*)[\s]+service[\s]+has[\s]+been[\s]+(?<fld21>.*)$" }
				id => "message-SW_AUDIT_LOG:04"
				add_field => {
					"[event][id]" => "SW_AUDIT_LOG:04"
					"[rsa][message][id1]" => "SW_AUDIT_LOG:04"
					"[event][categoryid]" => "1605020000"
					"[logstash][fullDateTimeString]" => "%{fld1} %{fld2} %{fld3} %{fld4} %{fld5} %{fld6}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "yyyy M d H m s" ] }
			}
		}
		# MESSAGE SW_AUDIT_LOG:05
		# line in RSA: SW_AUDIT_LOG^^<fld1>-<fld2>-<fld3> <fld4>:<fld5>:<fld6>^^<fld7>^^<username>^^<severity>^^<hostip>^^{<fld14>-<fld15>-<fld16> <fld17>:<fld18>:<fld19>|(null)}^^<fld20>^^<domain_id>^^Database Healthcheck (<info>)
		if ![logstash][messagefound] {
			grok {
				match => { "message" => "^SW_AUDIT_LOG\^\^(?<fld1>[^\-]*)\-(?<fld2>[^\-]*)\-(?<fld3>[^\s]*)[\s]+(?<fld4>[^:]*):(?<fld5>[^:]*):(?<fld6>[^\^]*)\^\^(?<fld7>[^\^]*)\^\^(?<username>[^\^]*)\^\^(?<severity>[^\^]*)\^\^(?<hostip>[^\^]*)\^\^((?<fld14>[^\-]*)\-(?<fld15>[^\-]*)\-(?<fld16>[^\s]*)[\s]+(?<fld17>[^:]*):(?<fld18>[^:]*):(?<fld19>[^\^]*)|\(null\))\^\^(?<fld20>[^\^]*)\^\^(?<domain_id>[^\^]*)\^\^Database[\s]+Healthcheck[\s]+\((?<info>[^\)]*)\)$" }
				id => "message-SW_AUDIT_LOG:05"
				add_field => {
					"[event][id]" => "SW_AUDIT_LOG:05"
					"[rsa][message][id1]" => "SW_AUDIT_LOG:05"
					"[event][categoryid]" => "1605030000"
					"[logstash][fullDateTimeString]" => "%{fld1} %{fld2} %{fld3} %{fld4} %{fld5} %{fld6}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "yyyy M d H m s" ] }
			}
		}
		# MESSAGE SW_AUDIT_LOG:06
		# line in RSA: SW_AUDIT_LOG^^<fld1>-<fld2>-<fld3> <fld4>:<fld5>:<fld6>^^<serial_number>^^<username>^^<severity>^^<hostip>^^{<fld14>-<fld15>-<fld16> <fld17>:<fld18>:<fld19>|(null)}^^<fld20>^^<id>^^Report data summarization started. <info>
		if ![logstash][messagefound] {
			grok {
				match => { "message" => "^SW_AUDIT_LOG\^\^(?<fld1>[^\-]*)\-(?<fld2>[^\-]*)\-(?<fld3>[^\s]*)[\s]+(?<fld4>[^:]*):(?<fld5>[^:]*):(?<fld6>[^\^]*)\^\^(?<serial_number>[^\^]*)\^\^(?<username>[^\^]*)\^\^(?<severity>[^\^]*)\^\^(?<hostip>[^\^]*)\^\^((?<fld14>[^\-]*)\-(?<fld15>[^\-]*)\-(?<fld16>[^\s]*)[\s]+(?<fld17>[^:]*):(?<fld18>[^:]*):(?<fld19>[^\^]*)|\(null\))\^\^(?<fld20>[^\^]*)\^\^(?<id>[^\^]*)\^\^Report[\s]+data[\s]+summarization[\s]+started\.[\s]+(?<info>.*)$" }
				id => "message-SW_AUDIT_LOG:06"
				add_field => {
					"[event][id]" => "SW_AUDIT_LOG:06"
					"[rsa][message][id1]" => "SW_AUDIT_LOG:06"
					"[event][categoryid]" => "1605020000"
					"[logstash][fullDateTimeString]" => "%{fld1} %{fld2} %{fld3} %{fld4} %{fld5} %{fld6}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "yyyy M d H m s" ] }
			}
		}
		# MESSAGE SW_AUDIT_LOG:07
		# line in RSA: SW_AUDIT_LOG^^<fld1>-<fld2>-<fld3> <fld4>:<fld5>:<fld6>^^<fld7>^^<username>^^<severity>^^<hostip>^^{<fld14>-<fld15>-<fld16> <fld17>:<fld18>:<fld19>|(null)}^^<fld20>^^<domain_id>^^Raw syslog file upload completed. <info>
		if ![logstash][messagefound] {
			grok {
				match => { "message" => "^SW_AUDIT_LOG\^\^(?<fld1>[^\-]*)\-(?<fld2>[^\-]*)\-(?<fld3>[^\s]*)[\s]+(?<fld4>[^:]*):(?<fld5>[^:]*):(?<fld6>[^\^]*)\^\^(?<fld7>[^\^]*)\^\^(?<username>[^\^]*)\^\^(?<severity>[^\^]*)\^\^(?<hostip>[^\^]*)\^\^((?<fld14>[^\-]*)\-(?<fld15>[^\-]*)\-(?<fld16>[^\s]*)[\s]+(?<fld17>[^:]*):(?<fld18>[^:]*):(?<fld19>[^\^]*)|\(null\))\^\^(?<fld20>[^\^]*)\^\^(?<domain_id>[^\^]*)\^\^Raw[\s]+syslog[\s]+file[\s]+upload[\s]+completed\.[\s]+(?<info>.*)$" }
				id => "message-SW_AUDIT_LOG:07"
				add_field => {
					"[event][id]" => "SW_AUDIT_LOG:07"
					"[rsa][message][id1]" => "SW_AUDIT_LOG:07"
					"[event][categoryid]" => "1605030000"
					"[logstash][fullDateTimeString]" => "%{fld1} %{fld2} %{fld3} %{fld4} %{fld5} %{fld6}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "yyyy M d H m s" ] }
			}
		}
		# MESSAGE SW_AUDIT_LOG:08
		# line in RSA: SW_AUDIT_LOG^^<fld1>-<fld2>-<fld3> <fld4>:<fld5>:<fld6>^^<fld7>^^<username>^^<severity>^^<hostip>^^{<fld14>-<fld15>-<fld16> <fld17>:<fld18>:<fld19>|(null)}^^<fld20>^^<domain_id>^^Shutting down <info>
		if ![logstash][messagefound] {
			grok {
				match => { "message" => "^SW_AUDIT_LOG\^\^(?<fld1>[^\-]*)\-(?<fld2>[^\-]*)\-(?<fld3>[^\s]*)[\s]+(?<fld4>[^:]*):(?<fld5>[^:]*):(?<fld6>[^\^]*)\^\^(?<fld7>[^\^]*)\^\^(?<username>[^\^]*)\^\^(?<severity>[^\^]*)\^\^(?<hostip>[^\^]*)\^\^((?<fld14>[^\-]*)\-(?<fld15>[^\-]*)\-(?<fld16>[^\s]*)[\s]+(?<fld17>[^:]*):(?<fld18>[^:]*):(?<fld19>[^\^]*)|\(null\))\^\^(?<fld20>[^\^]*)\^\^(?<domain_id>[^\^]*)\^\^Shutting[\s]+down[\s]+(?<info>.*)$" }
				id => "message-SW_AUDIT_LOG:08"
				add_field => {
					"[event][id]" => "SW_AUDIT_LOG:08"
					"[rsa][message][id1]" => "SW_AUDIT_LOG:08"
					"[event][categoryid]" => "1605030000"
					"[logstash][fullDateTimeString]" => "%{fld1} %{fld2} %{fld3} %{fld4} %{fld5} %{fld6}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "yyyy M d H m s" ] }
			}
		}
		# MESSAGE SW_AUDIT_LOG:09
		# line in RSA: SW_AUDIT_LOG^^<fld1>-<fld2>-<fld3> <fld4>:<fld5>:<fld6>^^<fld7>^^<username>^^<severity>^^<hostip>^^{<fld14>-<fld15>-<fld16> <fld17>:<fld18>:<fld19>|(null)}^^<fld20>^^<domain_id>^^Raw Syslog files selected for upload: <info>
		if ![logstash][messagefound] {
			grok {
				match => { "message" => "^SW_AUDIT_LOG\^\^(?<fld1>[^\-]*)\-(?<fld2>[^\-]*)\-(?<fld3>[^\s]*)[\s]+(?<fld4>[^:]*):(?<fld5>[^:]*):(?<fld6>[^\^]*)\^\^(?<fld7>[^\^]*)\^\^(?<username>[^\^]*)\^\^(?<severity>[^\^]*)\^\^(?<hostip>[^\^]*)\^\^((?<fld14>[^\-]*)\-(?<fld15>[^\-]*)\-(?<fld16>[^\s]*)[\s]+(?<fld17>[^:]*):(?<fld18>[^:]*):(?<fld19>[^\^]*)|\(null\))\^\^(?<fld20>[^\^]*)\^\^(?<domain_id>[^\^]*)\^\^Raw[\s]+Syslog[\s]+files[\s]+selected[\s]+for[\s]+upload:[\s]+(?<info>.*)$" }
				id => "message-SW_AUDIT_LOG:09"
				add_field => {
					"[event][id]" => "SW_AUDIT_LOG:09"
					"[rsa][message][id1]" => "SW_AUDIT_LOG:09"
					"[event][categoryid]" => "1605030000"
					"[logstash][fullDateTimeString]" => "%{fld1} %{fld2} %{fld3} %{fld4} %{fld5} %{fld6}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "yyyy M d H m s" ] }
			}
		}
		# MESSAGE SW_AUDIT_LOG:10
		# line in RSA: SW_AUDIT_LOG^^<fld1>-<fld2>-<fld3> <fld4>:<fld5>:<fld6>^^<fld7>^^<username>^^<severity>^^<hostip>^^{<fld14>-<fld15>-<fld16> <fld17>:<fld18>:<fld19>|(null)}^^<fld20>^^<domain_id>^^Report data summarized. <info>
		if ![logstash][messagefound] {
			grok {
				match => { "message" => "^SW_AUDIT_LOG\^\^(?<fld1>[^\-]*)\-(?<fld2>[^\-]*)\-(?<fld3>[^\s]*)[\s]+(?<fld4>[^:]*):(?<fld5>[^:]*):(?<fld6>[^\^]*)\^\^(?<fld7>[^\^]*)\^\^(?<username>[^\^]*)\^\^(?<severity>[^\^]*)\^\^(?<hostip>[^\^]*)\^\^((?<fld14>[^\-]*)\-(?<fld15>[^\-]*)\-(?<fld16>[^\s]*)[\s]+(?<fld17>[^:]*):(?<fld18>[^:]*):(?<fld19>[^\^]*)|\(null\))\^\^(?<fld20>[^\^]*)\^\^(?<domain_id>[^\^]*)\^\^Report[\s]+data[\s]+summarized\.[\s]+(?<info>.*)$" }
				id => "message-SW_AUDIT_LOG:10"
				add_field => {
					"[event][id]" => "SW_AUDIT_LOG:10"
					"[rsa][message][id1]" => "SW_AUDIT_LOG:10"
					"[event][categoryid]" => "1605030000"
					"[logstash][fullDateTimeString]" => "%{fld1} %{fld2} %{fld3} %{fld4} %{fld5} %{fld6}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "yyyy M d H m s" ] }
			}
		}
		# MESSAGE SW_AUDIT_LOG:11
		# line in RSA: SW_AUDIT_LOG^^<fld1>-<fld2>-<fld3> <fld4>:<fld5>:<fld6>^^<fld7>^^<username>^^<severity>^^<hostip>^^{<fld14>-<fld15>-<fld16> <fld17>:<fld18>:<fld19>|(null)}^^<fld20>^^<domain_id>^^<event_description>
		if ![logstash][messagefound] {
			grok {
				match => { "message" => "^SW_AUDIT_LOG\^\^(?<fld1>[^\-]*)\-(?<fld2>[^\-]*)\-(?<fld3>[^\s]*)[\s]+(?<fld4>[^:]*):(?<fld5>[^:]*):(?<fld6>[^\^]*)\^\^(?<fld7>[^\^]*)\^\^(?<username>[^\^]*)\^\^(?<severity>[^\^]*)\^\^(?<hostip>[^\^]*)\^\^((?<fld14>[^\-]*)\-(?<fld15>[^\-]*)\-(?<fld16>[^\s]*)[\s]+(?<fld17>[^:]*):(?<fld18>[^:]*):(?<fld19>[^\^]*)|\(null\))\^\^(?<fld20>[^\^]*)\^\^(?<domain_id>[^\^]*)\^\^(?<event_description>.*)$" }
				id => "message-SW_AUDIT_LOG:11"
				add_field => {
					"[event][id]" => "SW_AUDIT_LOG:11"
					"[rsa][message][id1]" => "SW_AUDIT_LOG:11"
					"[event][categoryid]" => "1605030000"
					"[logstash][fullDateTimeString]" => "%{fld1} %{fld2} %{fld3} %{fld4} %{fld5} %{fld6}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "yyyy M d H m s" ] }
			}
		}
	}


################## END OF MESSAGES ##################

# End of the filter block
}


output {
#	if [logstash][headerfound] and [logstash][messagefound] {
#		elasticsearch {
#			hosts => ["https://elasticxxxxxx"]
#			index => "%{[observer][product]}-%{+YYYY.MM.dd}"
#			user => "logstash"
#			password => "abc"	# Better use keystore, cf https://www.elastic.co/guide/en/logstash/master/keystore.html
#			manage_template => true
#			template => "es-mapping-v20_sonicwallgmsmsg.json"
#			template_name => "sonicwallgms_template"
#			template_overwrite => true
#		}
#	} else {
#		# using a file output for logs that were not parsed correctly
#		# should you chose to send it to elasticsearch, please read https://discuss.elastic.co/t/latency-with-2-elasticsearch-systems/170074/2
#		file { path => "failed_logs-%{[observer][product]}-%{+YYYY-MM-dd}" }
#	}
	stdout {
		codec => rubydebug
	}
}

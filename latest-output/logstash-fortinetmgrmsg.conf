# Config file generated by RSA2ELK, see https://github.com/blookot/rsa2elk 
# Author: Vincent Maury
# Check all Netwitness parsers: https://github.com/netwitness/nw-logparsers/tree/master/devices/ (license: Apache 2.0)
# Check this link to search for source configuration guides: https://rsa.jiveon.com/community/products/netwitness/integrations/event-sources

##########
# CAUTION: check the "path" in input and "dictionary_path" in filter, as well as the "template" path in the elasticsearch output or "path" in the file output
##########

input {
#	syslog {
#		port => 514
#	}
#	file {
#		path => "/var/log/example.log"
#		start_position => "beginning"
#		sincedb_path => "/dev/null"
#	}
	generator {
		count => 1
		message => "a log line to test out"
	}
#	kafka {
#		codec => "json"
#		bootstrap_servers => "192.168.30.13:9092"
#		topics => ["mytopic"]
#		security_protocol => "SSL"
#		ssl_key_password => "{ssl_password}"
#		ssl_keystore_location => "/{keystore-absolute-path}"
#		ssl_keystore_password => "{keystore_password}"
#		ssl_truststore_location => "/{truststore-absolute-path}"
#		ssl_truststore_password => "{truststore_password}"
#	}
}

# Renaming a couple of fields
filter {
	mutate {
		rename => {
			"message" => "[event][original]"
			"host" => "[logstash][host]"
		}
	}
}

# Setting the device name and group
filter {
	mutate {
		add_field => {
			"[observer][product]" => "fortinetmgr"
			"[observer][name]" => "Fortinet Manager/Analyzer"
			"[observer][type]" => "Firewall"
		}
	}
}


# One single filter block for all headers and messages
filter {

################## HEADERS ##################

	# HEADER 0001
	# line in RSA: date=<hdate> time=<htime> devname=<hdevice> device_id=<hfld1> log_id=<id> type=<hfld2> subtype=<hfld3> pri=<hseverity> <!payload>
	if ![logstash][headerfound] {
		dissect {
			mapping => { "[event][original]" => "date=%{hdate} time=%{htime} devname=%{hdevice} device_id=%{hfld1} log_id=%{id} type=%{hfld2} subtype=%{hfld3} pri=%{hseverity} %{message}" }
			id => "header-0001"
			add_field => {
				"[rsa][header][id]" => "0001"
				"[rsa][message][id2]" => "%{hfld2}_fortinetmgr"
				"[logstash][headerfound]" => true
			}
		}
	}
	# HEADER 0002
	# line in RSA: logver=<hfld1> date=<hdate> time=<htime> log_id=<id> <!payload>
	if ![logstash][headerfound] {
		dissect {
			mapping => { "[event][original]" => "logver=%{hfld1} date=%{hdate} time=%{htime} log_id=%{id} %{message}" }
			id => "header-0002"
			add_field => {
				"[rsa][header][id]" => "0002"
				"[rsa][message][id2]" => "generic_fortinetmgr"
				"[logstash][headerfound]" => true
			}
		}
	}
	# HEADER 0003
	# line in RSA: date=<hdate> time=<htime> logver=<fld1> <!payload>
	if ![logstash][headerfound] {
		dissect {
			mapping => { "[event][original]" => "date=%{hdate} time=%{htime} logver=%{fld1} %{message}" }
			id => "header-0003"
			add_field => {
				"[rsa][header][id]" => "0003"
				"[rsa][message][id2]" => "generic_fortinetmgr"
				"[logstash][headerfound]" => true
			}
		}
	}
	# HEADER 0004
	# line in RSA: logver=<hfld1> dtime=<hdatetime> devid=<hfld2> devname=<hdevice> <!payload>
	if ![logstash][headerfound] {
		dissect {
			mapping => { "[event][original]" => "logver=%{hfld1} dtime=%{hdatetime} devid=%{hfld2} devname=%{hdevice} %{message}" }
			id => "header-0004"
			add_field => {
				"[rsa][header][id]" => "0004"
				"[rsa][message][id2]" => "generic_fortinetmgr_1"
				"[logstash][headerfound]" => true
			}
		}
	}
	# HEADER 0005
	# line in RSA: logver=<hfld1> devname="<hdevice>" devid="<hfld2>" <!payload>
	if ![logstash][headerfound] {
		dissect {
			mapping => { "[event][original]" => "logver=%{hfld1} devname=\"%{hdevice}\" devid=\"%{hfld2}\" %{message}" }
			id => "header-0005"
			add_field => {
				"[rsa][header][id]" => "0005"
				"[rsa][message][id2]" => "generic_fortinetmgr_1"
				"[logstash][headerfound]" => true
			}
		}
	}



################## MsgId2 to Parser ##################

	translate {
		field => "[rsa][message][id2]"
		destination => "[logstash][msgparser][id]"
		dictionary_path => "msgid2parserid-fortinetmgrmsg.json"
		fallback => ""
		override => true
	}


################## MESSAGES ##################

	if [logstash][msgparser][id] == "event_fortinetmgr" {
		# MESSAGE fortinetmgr:01
		# line in RSA:  user=<fld1> adom=<domain> user=<username> ui=<fld2> action=<action> status=<event_state> msg="<event_description>"
		if ![logstash][messagefound] {
			dissect {
				mapping => { "message" => "user=%{fld1} adom=%{domain} user=%{username} ui=%{fld2} action=%{action} status=%{event_state} msg=\"%{event_description}\"" }
				id => "message-fortinetmgr:01"
				add_field => {
				"event_source" => "%{hdevice}"
				"hardware_id" => "%{hfld1}"
				"event_type" => "%{hlog_type}"
				"category" => "%{hfld3}"
				"severity" => "%{hseverity}"
					"[event][id]" => "fortinetmgr:01"
					"[rsa][message][id1]" => "fortinetmgr:01"
					"[event][categoryid]" => "1803000000"
					"[logstash][fullDateTimeString]" => "%{hdate} %{htime}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "yyyy-M-d H:m:s" ] }
			}
		}
		# MESSAGE fortinetmgr
		# line in RSA:  user=<username> adom=<domain> msg="<event_description>"
		if ![logstash][messagefound] {
			dissect {
				mapping => { "message" => "user=%{username} adom=%{domain} msg=\"%{event_description}\"" }
				id => "message-fortinetmgr"
				add_field => {
				"event_source" => "%{hdevice}"
				"hardware_id" => "%{hfld1}"
				"event_type" => "%{hlog_type}"
				"category" => "%{hfld3}"
				"severity" => "%{hseverity}"
					"[event][id]" => "fortinetmgr"
					"[rsa][message][id1]" => "fortinetmgr"
					"[event][categoryid]" => "1803000000"
					"[logstash][fullDateTimeString]" => "%{hdate} %{htime}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "yyyy-M-d H:m:s" ] }
			}
		}
		# MESSAGE fortinetmgr:04
		# line in RSA:  user="<username>" userfrom=<fld7> msg="{User|user} '<fld3>' with profile '<fld4>' <fld5> from <fld6>(<hostip>){."|"} { adminprof=<fld2> sid=<sid> user_type="<profile>" | adminprof=<fld2>}
		if ![logstash][messagefound] {
			grok {
				match => { "message" => "^[\s]*user=\"(?<username>[^\"]*)\"[\s]+userfrom=(?<fld7>[^\s]*)[\s]+msg=\"(User|user)[\s]+'(?<fld3>[^']*)'[\s]+with[\s]+profile[\s]+'(?<fld4>[^']*)'[\s]+(?<fld5>[^\s]*)[\s]+from[\s]+(?<fld6>[^\(]*)\((?<hostip>[^\)]*)\)(\.\"|\")[\s]+([\s]*adminprof=(?<fld2>[^\s]*)[\s]+sid=(?<sid>[^\s]*)[\s]+user_type=\"(?<profile>[^\"]*)\"[\s]+|[\s]*adminprof=(?<fld2>.*))$" }
				id => "message-fortinetmgr:04"
				add_field => {
				"event_source" => "%{hdevice}"
				"hardware_id" => "%{hfld1}"
				"event_type" => "%{hlog_type}"
				"category" => "%{hfld3}"
				"severity" => "%{hseverity}"
					"[event][id]" => "fortinetmgr:04"
					"[rsa][message][id1]" => "fortinetmgr:04"
					"[event][categoryid]" => "1605000000"
					"[logstash][fullDateTimeString]" => "%{hdate} %{htime}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "yyyy-M-d H:m:s" ] }
			}
		}
		# MESSAGE fortinetmgr:02
		# line in RSA:  user=<username> userfrom=<fld4> msg="<event_description>" adminprof=<fld2>
		if ![logstash][messagefound] {
			dissect {
				mapping => { "message" => "user=%{username} userfrom=%{fld4} msg=\"%{event_description}\" adminprof=%{fld2}" }
				id => "message-fortinetmgr:02"
				add_field => {
				"event_source" => "%{hdevice}"
				"hardware_id" => "%{hfld1}"
				"event_type" => "%{hlog_type}"
				"category" => "%{hfld3}"
				"severity" => "%{hseverity}"
					"[event][id]" => "fortinetmgr:02"
					"[rsa][message][id1]" => "fortinetmgr:02"
					"[event][categoryid]" => "1803000000"
					"[logstash][fullDateTimeString]" => "%{hdate} %{htime}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "yyyy-M-d H:m:s" ] }
			}
		}
		# MESSAGE fortinetmgr:03
		# line in RSA:  user="<username>" msg="Login from ssh:<fld1> for <fld2> from <saddr> port <sport>" remote_ip="<daddr>" remote_port=<dport> valid=<fld3> authmsg="<result>" extrainfo=<fld5>
		if ![logstash][messagefound] {
			dissect {
				mapping => { "message" => "user=\"%{username}\" msg=\"Login from ssh:%{fld1} for %{fld2} from %{saddr} port %{sport}\" remote_ip=\"%{daddr}\" remote_port=%{dport} valid=%{fld3} authmsg=\"%{result}\" extrainfo=%{fld5}" }
				id => "message-fortinetmgr:03"
				add_field => {
				"event_source" => "%{hdevice}"
				"hardware_id" => "%{hfld1}"
				"event_type" => "%{hlog_type}"
				"category" => "%{hfld3}"
				"severity" => "%{hseverity}"
					"[event][id]" => "fortinetmgr:03"
					"[rsa][message][id1]" => "fortinetmgr:03"
					"[event][categoryid]" => "1605000000"
					"[logstash][fullDateTimeString]" => "%{hdate} %{htime}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "yyyy-M-d H:m:s" ] }
			}
		}
		# MESSAGE fortinetmgr:05
		# line in RSA: user="<username>" userfrom="<fld1>"{msg="dev=<fld2>,vdom=<fld3>,type=<fld4>,key=<fld5>,act=<action>,pkgname=<fld7>,allowaccess=<fld8>" adom="<domain>"|msg="<event_description>" adom="<domain>"}
		if ![logstash][messagefound] {
			grok {
				match => { "message" => "^user=\"(?<username>[^\"]*)\"[\s]+userfrom=\"(?<fld1>[^\"]*)\"(msg=\"dev=(?<fld2>[^,]*),vdom=(?<fld3>[^,]*),type=(?<fld4>[^,]*),key=(?<fld5>[^,]*),act=(?<action>[^,]*),pkgname=(?<fld7>[^,]*),allowaccess=(?<fld8>[^\"]*)\"[\s]+adom=\"(?<domain>[^\"]*)\"|msg=\"(?<event_description>[^\"]*)\"[\s]+adom=\"(?<domain>[^\"]*)\")$" }
				id => "message-fortinetmgr:05"
				add_field => {
				"event_source" => "%{hdevice}"
				"hardware_id" => "%{hfld1}"
				"event_type" => "%{hlog_type}"
				"category" => "%{hfld3}"
				"severity" => "%{hseverity}"
					"[event][id]" => "fortinetmgr:05"
					"[rsa][message][id1]" => "fortinetmgr:05"
					"[event][categoryid]" => "1801000000"
					"[logstash][fullDateTimeString]" => "%{hdate} %{htime}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "yyyy-M-d H:m:s" ] }
			}
		}
		# MESSAGE event_fortinetmgr_tvm
		# line in RSA:  desc=<event_description> user=<username> userfrom=<fld1> msg=<info> action=<action> adom=<domain> session_id=<sessionid>
		if ![logstash][messagefound] {
			dissect {
				mapping => { "message" => "desc=%{event_description} user=%{username} userfrom=%{fld1} msg=%{info} action=%{action} adom=%{domain} session_id=%{sessionid}" }
				id => "message-event_fortinetmgr_tvm"
				add_field => {
				"event_source" => "%{hdevice}"
				"hardware_id" => "%{hfld1}"
				"event_type" => "%{hfld2}"
				"category" => "%{hfld3}"
				"severity" => "%{hseverity}"
					"[event][id]" => "event_fortinetmgr_tvm"
					"[rsa][message][id1]" => "event_fortinetmgr_tvm"
					"[event][categoryid]" => "1605000000"
					"[logstash][fullDateTimeString]" => "%{hdate} %{htime}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "yyyy-M-d H:m:s" ] }
			}
		}
	}
	# PARSER msgParserId7
	# line in RSA: devid=<hardware_id> devname=<event_source> logid=<id> type=<event_type> subtype=<category> level=<severity> vd=<vsys> srcip=<saddr> srcport=<sport> srcintf=<sinterface> dstip=<daddr> dstport=<dport> dstintf=<dinterface> poluuid=<fld5> sessionid=<sessionid> proto=<fld6> action=<action> policyid=<policy_id> trandisp=<context> duration=<duration> sentbyte=<sbytes> rcvdbyte=<rbytes> devtype=<fld7> osname=<os> osversion=<version> mastersrcmac=<fld8> srcmac=<smacaddr> crscore=<reputation_num> craction=<fld9> crlevel=<fld10> eventtype=<vendor_event_cat> user=<username> service=<network_service> hostname=<hostname> profile=<rulename> reqtype=<fld11> url=<url> direction=<direction> msg=<event_description> method=<fld12> cat=<fcatnum> catdesc=<filter> device_id=<hardware_id> log_id=<id> pri=<severity> userfrom=<fld30> adminprof=<fld13> timezone=<timezone> main_type=<fld37> trigger_policy=<fld39> sub_type=<category> severity_level=<fld101> policy=<policyname> src=<saddr> src_port=<sport> dst=<daddr> dst_port=<dport> http_method=<web_method> http_url=<web_query> http_host=<web_ref_domain> http_agent=<agent> http_session_id=<sessionid> signature_subclass=<fld14> signature_id=<sigid> srccountry=<location_src> content_switch_name=<fld15> server_pool_name=<fld16> false_positive_mitigation=<fld17> user_name=<username> monitor_status=<fld18> http_refer=<web_referer> http_version=<fld19> dev_id=<fld100> threat_weight=<fld20> history_threat_weight=<fld21> threat_level=<threat_val> ftp_mode=<fld22> ftp_cmd=<fld23> cipher_suite=<fld24> msg_id=<fld25>
	else if [logstash][msgparser][id] == "msgParserId7" {
		dissect {
			mapping => { "message" => "devid=%{hardware_id} devname=%{event_source} logid=%{id} type=%{event_type} subtype=%{category} level=%{severity} vd=%{vsys} srcip=%{saddr} srcport=%{sport} srcintf=%{sinterface} dstip=%{daddr} dstport=%{dport} dstintf=%{dinterface} poluuid=%{fld5} sessionid=%{sessionid} proto=%{fld6} action=%{action} policyid=%{policy_id} trandisp=%{context} duration=%{duration} sentbyte=%{sbytes} rcvdbyte=%{rbytes} devtype=%{fld7} osname=%{os} osversion=%{version} mastersrcmac=%{fld8} srcmac=%{smacaddr} crscore=%{reputation_num} craction=%{fld9} crlevel=%{fld10} eventtype=%{vendor_event_cat} user=%{username} service=%{network_service} hostname=%{hostname} profile=%{rulename} reqtype=%{fld11} url=%{url} direction=%{direction} msg=%{event_description} method=%{fld12} cat=%{fcatnum} catdesc=%{filter} device_id=%{hardware_id} log_id=%{id} pri=%{severity} userfrom=%{fld30} adminprof=%{fld13} timezone=%{timezone} main_type=%{fld37} trigger_policy=%{fld39} sub_type=%{category} severity_level=%{fld101} policy=%{policyname} src=%{saddr} src_port=%{sport} dst=%{daddr} dst_port=%{dport} http_method=%{web_method} http_url=%{web_query} http_host=%{web_ref_domain} http_agent=%{agent} http_session_id=%{sessionid} signature_subclass=%{fld14} signature_id=%{sigid} srccountry=%{location_src} content_switch_name=%{fld15} server_pool_name=%{fld16} false_positive_mitigation=%{fld17} user_name=%{username} monitor_status=%{fld18} http_refer=%{web_referer} http_version=%{fld19} dev_id=%{fld100} threat_weight=%{fld20} history_threat_weight=%{fld21} threat_level=%{threat_val} ftp_mode=%{fld22} ftp_cmd=%{fld23} cipher_suite=%{fld24} msg_id=%{fld25}" }
			id => "msgParserId7"
			add_field => {
				"[logstash][fullDateTimeString]" => "%{hdate} %{htime}"
				"[logstash][messagefound]" => true
			}
		}
		if [logstash][fullDateTimeString] {
			date { match => [ "[logstash][fullDateTimeString]", "yyyy-M-d H:m:s" ] }
		}
	}
	# PARSER msgParserId8
	# line in RSA: vd=<vsys> date=<fld1> time=<fld2> logid=<id> type=<event_type> subtype=<category> level=<severity> eventtime=<event_time_string> logtime=<fld35> srcip=<saddr> srcport=<sport> srcintf=<sinterface> srcintfrole=<fld30> dstip=<daddr> dstport=<dport> dstintf=<dinterface> dstintfrole=<fld31> poluuid=<fld5> sessionid=<sessionid> proto=<fld6> action=<action> policyid=<policy_id> policytype=<fld34> crscore=<reputation_num> craction=<fld9> crlevel=<fld10> appcat=<fld33> service=<network_service> srccountry=<location_src> dstcountry=<location_dst> trandisp=<context> tranip=<dtransaddr> tranport=<dtransport> duration=<duration> sentbyte=<sbytes> rcvdbyte=<rbytes> sentpkt=<fld15> app=<obj_name>
	else if [logstash][msgparser][id] == "msgParserId8" {
		dissect {
			mapping => { "message" => "vd=%{vsys} date=%{fld1} time=%{fld2} logid=%{id} type=%{event_type} subtype=%{category} level=%{severity} eventtime=%{event_time_string} logtime=%{fld35} srcip=%{saddr} srcport=%{sport} srcintf=%{sinterface} srcintfrole=%{fld30} dstip=%{daddr} dstport=%{dport} dstintf=%{dinterface} dstintfrole=%{fld31} poluuid=%{fld5} sessionid=%{sessionid} proto=%{fld6} action=%{action} policyid=%{policy_id} policytype=%{fld34} crscore=%{reputation_num} craction=%{fld9} crlevel=%{fld10} appcat=%{fld33} service=%{network_service} srccountry=%{location_src} dstcountry=%{location_dst} trandisp=%{context} tranip=%{dtransaddr} tranport=%{dtransport} duration=%{duration} sentbyte=%{sbytes} rcvdbyte=%{rbytes} sentpkt=%{fld15} app=%{obj_name}" }
			id => "msgParserId8"
			add_field => {
				"event_source" => "%{hdevice}"
				"hardware_id" => "%{hfld2}"
				"[logstash][fullDateTimeString]" => "%{fld1} %{fld2}"
				"[logstash][messagefound]" => true
			}
		}
		if [logstash][fullDateTimeString] {
			date { match => [ "[logstash][fullDateTimeString]", "yyyy-M-d H:m:s" ] }
		}
	}


################## END OF MESSAGES ##################

# End of the filter block
}

# Enrich events using VALUEMAP
filter {
	translate {
		field => "[event_cat]"
		destination => "[event_cat_name]"
		dictionary => {
			"1302000000" => "Auth.Successful"
			"1301000000" => "Auth.Failures"
			"1401070000" => "User.Activity.Logoff"
		}
		fallback => "Other.Default"
		override => true
	}
}
filter {
	translate {
		field => "[result]"
		destination => "[event_cat]"
		dictionary => {
			"Accepted" => "1302000000"
			"Failed" => "1301000000"
			"login accepted" => "1302000000"
			"timed out" => "1401070000"
		}
		fallback => "1901000000"
		override => true
	}
}
filter {
	translate {
		field => "[fld6]"
		destination => "[protocol]"
		dictionary => {
			"3" => "GGP"
			"0" => "HOPOPT"
			"1" => "ICMP"
			"6" => "TCP"
			"17" => "UDP"
			"21" => "PRM"
			"HOPOPT" => "HOPOPT"
			"icmp" => "ICMP"
			"tcp" => "TCP"
			"udp" => "UDP"
			"prm" => "PRM"
		}
		fallback => ""
		override => true
	}
}


output {
#	if [logstash][headerfound] and [logstash][messagefound] {
#		elasticsearch {
#			hosts => ["https://elasticxxxxxx"]
#			index => "%{[observer][product]}-%{+YYYY.MM.dd}"
#			user => "logstash"
#			password => "abc"	# Better use keystore, cf https://www.elastic.co/guide/en/logstash/master/keystore.html
#			manage_template => true
#			template => "es-mapping-fortinetmgrmsg.json"
#			template_name => "fortinetmgr_template"
#			template_overwrite => true
#		}
#	} else {
#		# using a file output for logs that were not parsed correctly
#		# should you chose to send it to elasticsearch, please read https://discuss.elastic.co/t/latency-with-2-elasticsearch-systems/170074/2
#		file { path => "failed_logs-%{[observer][product]}-%{+YYYY-MM-dd}" }
#	}
	stdout {
		codec => rubydebug
	}
}

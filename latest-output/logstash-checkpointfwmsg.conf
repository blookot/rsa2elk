# Config file generated by RSA2ELK, see https://github.com/blookot/rsa2elk 
# Author: Vincent Maury
# Check all Netwitness parsers: https://github.com/netwitness/nw-logparsers/tree/master/devices/ (license: Apache 2.0)
# Check this link to search for source configuration guides: https://rsa.jiveon.com/community/products/netwitness/integrations/event-sources

##########
# CAUTION: check the "path" in input and "dictionary_path" in filter, as well as the "template" path in the elasticsearch output or "path" in the file output
##########

input {
#	syslog {
#		port => 514
#	}
#	file {
#		path => "/var/log/example.log"
#		start_position => "beginning"
#		sincedb_path => "/dev/null"
#	}
	generator {
		count => 1
		message => "a log line to test out"
	}
#	kafka {
#		codec => "json"
#		bootstrap_servers => "192.168.30.13:9092"
#		topics => ["mytopic"]
#		security_protocol => "SSL"
#		ssl_key_password => "{ssl_password}"
#		ssl_keystore_location => "/{keystore-absolute-path}"
#		ssl_keystore_password => "{keystore_password}"
#		ssl_truststore_location => "/{truststore-absolute-path}"
#		ssl_truststore_password => "{truststore_password}"
#	}
}

# Renaming a couple of fields
filter {
	mutate {
		rename => {
			"message" => "[event][original]"
			"host" => "[logstash][host]"
		}
	}
}

# Setting the device name and group
filter {
	mutate {
		add_field => {
			"[observer][product]" => "checkpointfw"
			"[observer][name]" => "Check Point Firewall"
			"[observer][type]" => "Firewall"
		}
	}
}


# One single filter block for all headers and messages
filter {

################## HEADERS ##################

	# HEADER 0001
	# line in RSA: <fld1> <year>-<month>-<date>T<time> <hhost> <gateway> - Log [ <hfld1> <!payload>
	if ![logstash][headerfound] {
		dissect {
			mapping => { "[event][original]" => "%{fld1} %{year}-%{month}-%{date}T%{time} %{hhost} %{gateway} - Log [ %{hfld1} %{message}" }
			id => "header-0001"
			add_field => {
				"[rsa][header][id]" => "0001"
				"[rsa][message][id2]" => "CHECKPOINT_SYSLOG"
				"[logstash][headerfound]" => true
			}
		}
	}



################## MsgId2 to Parser ##################

	translate {
		field => "[rsa][message][id2]"
		destination => "[logstash][msgparser][id]"
		dictionary_path => "msgid2parserid-checkpointfwmsg.json"
		fallback => ""
		override => true
	}


################## MESSAGES ##################

	# PARSER msgParserId0
	# line in RSA: Action=<action> UUid=<fld1> inzone=<fld1> outzone=<fld2> rule=<rule> rule_uid=<rule_uid> rule_name=<rulename> service_id=<fld3> src=<saddr> dst=<daddr> proto=<fld70> xlatesrc=<stransaddr> NAT_rulenum=<fld15> NAT_addtnl_rulenum=<fld14> src_machine_name=<shost> snid=<fld5> product=<product> service=<network_service> s_port=<sport> xlatesport=<stransport> product_family=<fld6> user=<username> src_user_name=<c_username> xlatedst=<dtransaddr> ICMP Code=<icmpcode> ICMP Type=<icmptype> dst_machine_name=<dhost> file_type=<filetype> malware_detected=<fld10> scanned=<fld11> threatcloud_malware=<fld12> message_info=<info> status=<event_state> product_family=<fld12> tcp_flags=<fld25> tcp_packet_out_of_state=<fld23> web_client_type=<fld24> resource=<fld27> session_id=<sessionid> reason=<result> verdict=<fld28> proxy_src_ip=<fld29> domain_name=<domain> auth_status=<result> auth_method=<authmethod> log_id=<fld30> reject_category=<event_description> peer gateway=<peer> vpn_feature_name=<fld31> community=<fld32> vpn_user=<fld33> mac_address=<macaddr> Hostname=<hostname> auth_encryption_methods=<encryption_type> client_version=<version> Severity=<severity> severity=<severity> subscription_stat_desc=<event_description> description=<event_description>
	if [logstash][msgparser][id] == "msgParserId0" {
		dissect {
			mapping => { "message" => "Action=%{action} UUid=%{fld1} inzone=%{fld1} outzone=%{fld2} rule=%{rule} rule_uid=%{rule_uid} rule_name=%{rulename} service_id=%{fld3} src=%{saddr} dst=%{daddr} proto=%{fld70} xlatesrc=%{stransaddr} NAT_rulenum=%{fld15} NAT_addtnl_rulenum=%{fld14} src_machine_name=%{shost} snid=%{fld5} product=%{product} service=%{network_service} s_port=%{sport} xlatesport=%{stransport} product_family=%{fld6} user=%{username} src_user_name=%{c_username} xlatedst=%{dtransaddr} ICMP Code=%{icmpcode} ICMP Type=%{icmptype} dst_machine_name=%{dhost} file_type=%{filetype} malware_detected=%{fld10} scanned=%{fld11} threatcloud_malware=%{fld12} message_info=%{info} status=%{event_state} product_family=%{fld12} tcp_flags=%{fld25} tcp_packet_out_of_state=%{fld23} web_client_type=%{fld24} resource=%{fld27} session_id=%{sessionid} reason=%{result} verdict=%{fld28} proxy_src_ip=%{fld29} domain_name=%{domain} auth_status=%{result} auth_method=%{authmethod} log_id=%{fld30} reject_category=%{event_description} peer gateway=%{peer} vpn_feature_name=%{fld31} community=%{fld32} vpn_user=%{fld33} mac_address=%{macaddr} Hostname=%{hostname} auth_encryption_methods=%{encryption_type} client_version=%{version} Severity=%{severity} severity=%{severity} subscription_stat_desc=%{event_description} description=%{event_description}" }
			id => "msgParserId0"
			add_field => {
				"[logstash][fullDateTimeString]" => "%{fld27}"
				"[logstash][messagefound]" => true
			}
		}
		if [logstash][fullDateTimeString] {
			date { match => [ "[logstash][fullDateTimeString]", "dMMMyyyy H:m:s" ] }
		}
	}


################## END OF MESSAGES ##################

# End of the filter block
}

# Enrich events using VALUEMAP
filter {
	translate {
		field => "[action]"
		destination => "[event_cat]"
		dictionary => {
			"accept" => "1801020000"
			"reject" => "1803000000"
			"drop" => "1803000000"
			"Deny" => "1803000000"
			"encrypt" => "1613030000"
			"decrypt" => "1613030000"
			"logout" => "1401070000"
			"keyinst" => "1304000000"
			"authcrypt" => "1304000000"
			"monitor" => "1801010000"
			"update" => "1304000000"
		}
		fallback => "1901000000"
		override => true
	}
}
filter {
	translate {
		field => "[event_cat]"
		destination => "[event_cat_name]"
		dictionary => {
			"1801020000" => "Network.Connections.Successful"
			"1803000000" => "Network.Denied Connections"
			"1401070000" => "User.Activity.Logoff"
			"1613030000" => "System.Crypto.Configuration"
			"1304000000" => "Auth.General"
			"1801010000" => "Network.Connections.Errors"
		}
		fallback => "Other.Default"
		override => true
	}
}
filter {
	translate {
		field => "[fld70]"
		destination => "[protocol]"
		dictionary => {
			"0" => "HOPOPT"
			"1" => "ICMP"
			"2" => "IGMP"
			"6" => "TCP"
			"17" => "UDP"
			"21" => "PRM"
			"HOPOPT" => "HOPOPT"
			"icmp" => "ICMP"
			"tcp" => "TCP"
			"udp" => "UDP"
			"prm" => "PRM"
		}
		fallback => ""
		override => true
	}
}


output {
#	if [logstash][headerfound] and [logstash][messagefound] {
#		elasticsearch {
#			hosts => ["https://elasticxxxxxx"]
#			index => "%{[observer][product]}-%{+YYYY.MM.dd}"
#			user => "logstash"
#			password => "abc"	# Better use keystore, cf https://www.elastic.co/guide/en/logstash/master/keystore.html
#			manage_template => true
#			template => "es-mapping-checkpointfwmsg.json"
#			template_name => "checkpointfw_template"
#			template_overwrite => true
#		}
#	} else {
#		# using a file output for logs that were not parsed correctly
#		# should you chose to send it to elasticsearch, please read https://discuss.elastic.co/t/latency-with-2-elasticsearch-systems/170074/2
#		file { path => "failed_logs-%{[observer][product]}-%{+YYYY-MM-dd}" }
#	}
	stdout {
		codec => rubydebug
	}
}

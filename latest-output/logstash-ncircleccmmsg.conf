# Config file generated by RSA2ELK, see https://github.com/blookot/rsa2elk 
# Author: Vincent Maury
# Check all Netwitness parsers: https://github.com/netwitness/nw-logparsers/tree/master/devices/ (license: Apache 2.0)
# Check this link to search for source configuration guides: https://rsa.jiveon.com/community/products/netwitness/integrations/event-sources

##########
# CAUTION: check the "path" in input and "dictionary_path" in filter, as well as the "template" path in the elasticsearch output or "path" in the file output
##########

input {
#	syslog {
#		port => 514
#	}
#	file {
#		path => "/var/log/example.log"
#		start_position => "beginning"
#		sincedb_path => "/dev/null"
#	}
	generator {
		count => 1
		message => "a log line to test out"
	}
#	kafka {
#		codec => "json"
#		bootstrap_servers => "192.168.30.13:9092"
#		topics => ["mytopic"]
#		security_protocol => "SSL"
#		ssl_key_password => "{ssl_password}"
#		ssl_keystore_location => "/{keystore-absolute-path}"
#		ssl_keystore_password => "{keystore_password}"
#		ssl_truststore_location => "/{truststore-absolute-path}"
#		ssl_truststore_password => "{truststore_password}"
#	}
}

# Renaming a couple of fields
filter {
	mutate {
		rename => {
			"message" => "[event][original]"
			"host" => "[logstash][host]"
		}
	}
}

# Setting the device name and group
filter {
	mutate {
		add_field => {
			"[observer][product]" => "ncircleccm"
			"[observer][name]" => "nCircle CCM"
			"[observer][type]" => "Configuration Management"
		}
	}
}


# One single filter block for all headers and messages
filter {

################## HEADERS ##################

	# HEADER 0001
	# line in RSA: <hfld1> <hfld2> <hfld3> <hfld4> <hfld5> Type: <messageid>, <!payload>
	if ![logstash][headerfound] {
		dissect {
			mapping => { "[event][original]" => "%{hfld1} %{hfld2} %{hfld3} %{hfld4} %{hfld5} Type: %{messageid}, %{message}" }
			id => "header-0001"
			add_field => {
				"[rsa][header][id]" => "0001"
				"[rsa][message][id2]" => "%{messageid}"
				"[logstash][headerfound]" => true
			}
		}
	}
	# HEADER 0002
	# line in RSA: <hfld1> <hfld2> <hfld3> <hfld4> <hfld5> <messageid>: <!payload>
	if ![logstash][headerfound] {
		dissect {
			mapping => { "[event][original]" => "%{hfld1} %{hfld2} %{hfld3} %{hfld4} %{hfld5} %{messageid}: %{message}" }
			id => "header-0002"
			add_field => {
				"[rsa][header][id]" => "0002"
				"[rsa][message][id2]" => "%{messageid}"
				"[logstash][headerfound]" => true
			}
		}
	}



################## MsgId2 to Parser ##################

	translate {
		field => "[rsa][message][id2]"
		destination => "[logstash][msgparser][id]"
		dictionary_path => "msgid2parserid-ncircleccmmsg.json"
		fallback => ""
		override => true
	}


################## MESSAGES ##################

	# PARSER msgParserId0
	# line in RSA: Timestamp: <fld1> <fld2> <fld3>, Event ID: <fld4>, IP: <hostip>, Host: <hostname>, MAC: <macaddr>, Compound Risk: <risk>, Event Risk: <fld9>, Host Criticality: <fld10> Event Severity: <severity> OS: <os>, Who Made The Change: <username>, Summary: <info> status: <event_state> Result: <result>
	if [logstash][msgparser][id] == "msgParserId0" {
		dissect {
			mapping => { "message" => "Timestamp: %{fld1} %{fld2} %{fld3}, Event ID: %{fld4}, IP: %{hostip}, Host: %{hostname}, MAC: %{macaddr}, Compound Risk: %{risk}, Event Risk: %{fld9}, Host Criticality: %{fld10} Event Severity: %{severity} OS: %{os}, Who Made The Change: %{username}, Summary: %{info} status: %{event_state} Result: %{result}" }
			id => "msgParserId0"
			add_field => {
				"ec_theme" => "Configuration"
				"event_source" => "%{hfld4}"
				"[logstash][fullDateTimeString]" => "%{fld1} %{fld2} %{fld3}"
				"[logstash][messagefound]" => true
			}
		}
		if [logstash][fullDateTimeString] {
			date { match => [ "[logstash][fullDateTimeString]", "M/d/yyyy H:m:s a" ] }
		}
	}
	# PARSER msgParserId1
	# line in RSA: Timestamp: <fld1> <fld2> <fld3>, Event ID: <fld4>, IP: <hostip>, Host: <hostname>, MAC: <macaddr>, Compound Risk: <risk>, Event Risk: <fld9>, Host Criticality: <fld10>, Event Severity: <severity>, OS: <os>, Who Made The Change: <username>, Summary: <info>
	else if [logstash][msgparser][id] == "msgParserId1" {
		dissect {
			mapping => { "message" => "Timestamp: %{fld1} %{fld2} %{fld3}, Event ID: %{fld4}, IP: %{hostip}, Host: %{hostname}, MAC: %{macaddr}, Compound Risk: %{risk}, Event Risk: %{fld9}, Host Criticality: %{fld10}, Event Severity: %{severity}, OS: %{os}, Who Made The Change: %{username}, Summary: %{info}" }
			id => "msgParserId1"
			add_field => {
				"ec_theme" => "Configuration"
				"event_source" => "%{hfld4}"
				"[logstash][fullDateTimeString]" => "%{fld1} %{fld2} %{fld3}"
				"[logstash][messagefound]" => true
			}
		}
		if [logstash][fullDateTimeString] {
			date { match => [ "[logstash][fullDateTimeString]", "M/d/yyyy H:m:s a" ] }
		}
	}
	else if [logstash][msgparser][id] == "PropertyChanged" {
		# MESSAGE PropertyChanged
		# line in RSA: Timestamp: <fld1> <fld2> <fld3>, Event ID: <fld4>, IP: <hostip>, Host: <hostname>, MAC: <macaddr>, Compound Risk: <risk>, Event Risk: <fld9>, Host Criticality: <fld10> Event Severity: <severity> OS: <os>, Who Made The Change: <username>, Summary:<info> Asset Status changed:<result>
		if ![logstash][messagefound] {
			dissect {
				mapping => { "message" => "Timestamp: %{fld1} %{fld2} %{fld3}, Event ID: %{fld4}, IP: %{hostip}, Host: %{hostname}, MAC: %{macaddr}, Compound Risk: %{risk}, Event Risk: %{fld9}, Host Criticality: %{fld10} Event Severity: %{severity} OS: %{os}, Who Made The Change: %{username}, Summary:%{info} Asset Status changed:%{result}" }
				id => "message-PropertyChanged"
				add_field => {
				"ec_activity" => "Modify"
				"ec_theme" => "Configuration"
				"event_source" => "%{hfld4}"
					"[event][id]" => "PropertyChanged"
					"[rsa][message][id1]" => "PropertyChanged"
					"[event][categoryid]" => "1701020000"
					"[logstash][fullDateTimeString]" => "%{fld1} %{fld2} %{fld3}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "M/d/yyyy H:m:s a" ] }
			}
		}
		# MESSAGE PropertyChanged:01
		# line in RSA: Timestamp: <fld1> <fld2> <fld3>, Event ID: <fld4>, IP: <hostip>, Host: <hostname>, MAC: <macaddr>, Compound Risk: <risk>, Event Risk: <fld9>, Host Criticality: <fld10> Event Severity: <severity> OS: <os>, Who Made The Change: <username>, Summary: <info>
		if ![logstash][messagefound] {
			dissect {
				mapping => { "message" => "Timestamp: %{fld1} %{fld2} %{fld3}, Event ID: %{fld4}, IP: %{hostip}, Host: %{hostname}, MAC: %{macaddr}, Compound Risk: %{risk}, Event Risk: %{fld9}, Host Criticality: %{fld10} Event Severity: %{severity} OS: %{os}, Who Made The Change: %{username}, Summary: %{info}" }
				id => "message-PropertyChanged:01"
				add_field => {
				"ec_activity" => "Modify"
				"ec_theme" => "Configuration"
				"event_source" => "%{hfld4}"
					"[event][id]" => "PropertyChanged:01"
					"[rsa][message][id1]" => "PropertyChanged:01"
					"[event][categoryid]" => "1701020000"
					"[logstash][fullDateTimeString]" => "%{fld1} %{fld2} %{fld3}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "M/d/yyyy H:m:s a" ] }
			}
		}
	}
	# PARSER msgParserId4
	# line in RSA: Timestamp: <fld1> <fld2> <fld3>, Event ID: <fld4>, IP: <hostip>, Host: <hostname>, MAC: <macaddr>, Compound Risk: <risk>, Event Risk: <fld9>, Host Criticality: <fld10>, Event Severity: <severity> OS: <os>, Who Made The Change: <username>, Summary: <info>
	else if [logstash][msgparser][id] == "msgParserId4" {
		dissect {
			mapping => { "message" => "Timestamp: %{fld1} %{fld2} %{fld3}, Event ID: %{fld4}, IP: %{hostip}, Host: %{hostname}, MAC: %{macaddr}, Compound Risk: %{risk}, Event Risk: %{fld9}, Host Criticality: %{fld10}, Event Severity: %{severity} OS: %{os}, Who Made The Change: %{username}, Summary: %{info}" }
			id => "msgParserId4"
			add_field => {
				"ec_theme" => "Configuration"
				"event_source" => "%{hfld4}"
				"[logstash][fullDateTimeString]" => "%{fld1} %{fld2} %{fld3}"
				"[logstash][messagefound]" => true
			}
		}
		if [logstash][fullDateTimeString] {
			date { match => [ "[logstash][fullDateTimeString]", "M/d/yyyy H:m:s a" ] }
		}
	}
	# PARSER msgParserId5
	# line in RSA: Timestamp: <fld1> <fld2> <fld3>, Event ID: <fld4>, IP: <hostip>, Host: <hostname>, MAC: <macaddr>, Compound Risk: <risk> Event Risk: <fld9>, Host Criticality: <fld10>, Event Severity: <severity>, OS: <os>, Who Made The Change: <username>, Summary: <info>
	else if [logstash][msgparser][id] == "msgParserId5" {
		dissect {
			mapping => { "message" => "Timestamp: %{fld1} %{fld2} %{fld3}, Event ID: %{fld4}, IP: %{hostip}, Host: %{hostname}, MAC: %{macaddr}, Compound Risk: %{risk} Event Risk: %{fld9}, Host Criticality: %{fld10}, Event Severity: %{severity}, OS: %{os}, Who Made The Change: %{username}, Summary: %{info}" }
			id => "msgParserId5"
			add_field => {
				"ec_theme" => "Configuration"
				"event_source" => "%{hfld4}"
				"[logstash][fullDateTimeString]" => "%{fld1} %{fld2} %{fld3}"
				"[logstash][messagefound]" => true
			}
		}
		if [logstash][fullDateTimeString] {
			date { match => [ "[logstash][fullDateTimeString]", "M/d/yyyy H:m:s a" ] }
		}
	}
	else if [logstash][msgparser][id] == "ID" {
		# MESSAGE ID
		# line in RSA: <fld1> Recovered: <disposition> Type: <event_type> Severity: <severity> Component: <agent> Host: <fld6> Failure Date: <fld7> Last Date: <fld8> Information: <event_description> Asset ID: <fld10> Network Profile: <fld11> Asset Group: <group_object> Meta Asset: <os> Task: <action> {(<fld14>) Recovery Information:<fld15>|(<fld14>)}
		if ![logstash][messagefound] {
			grok {
				match => { "message" => "^(?<fld1>[^\s]*)[\s]+Recovered:[\s]+(?<disposition>[^\s]*)[\s]+Type:[\s]+(?<event_type>[^\s]*)[\s]+Severity:[\s]+(?<severity>[^\s]*)[\s]+Component:[\s]+(?<agent>[^\s]*)[\s]+Host:[\s]+(?<fld6>[^\s]*)[\s]+Failure[\s]+Date:[\s]+(?<fld7>[^\s]*)[\s]+Last[\s]+Date:[\s]+(?<fld8>[^\s]*)[\s]+Information:[\s]+(?<event_description>[^\s]*)[\s]+Asset[\s]+ID:[\s]+(?<fld10>[^\s]*)[\s]+Network[\s]+Profile:[\s]+(?<fld11>[^\s]*)[\s]+Asset[\s]+Group:[\s]+(?<group_object>[^\s]*)[\s]+Meta[\s]+Asset:[\s]+(?<os>[^\s]*)[\s]+Task:[\s]+(?<action>[^\s]*)[\s]+(\((?<fld14>[^\)]*)\)[\s]+Recovery[\s]+Information:(?<fld15>.*)|\((?<fld14>[^\)]*)\))$" }
				id => "message-ID"
				add_field => {
				"event_source" => "%{hfld4}"
					"[event][id]" => "ID"
					"[rsa][message][id1]" => "ID"
					"[event][categoryid]" => "1604000000"
					"[logstash][fullDateTimeString]" => "%{fld8}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "M/d/yyyy H:m:s a" ] }
			}
		}
		# MESSAGE ID:01
		# line in RSA: <fld1> Recovered: <disposition> Type: <event_type> Severity: <severity> Component: <agent> Host: <fld6> Failure Date: <fld7> Last Date: <fld8> Information:<event_description>
		if ![logstash][messagefound] {
			dissect {
				mapping => { "message" => "%{fld1} Recovered: %{disposition} Type: %{event_type} Severity: %{severity} Component: %{agent} Host: %{fld6} Failure Date: %{fld7} Last Date: %{fld8} Information:%{event_description}" }
				id => "message-ID:01"
				add_field => {
				"event_source" => "%{hfld4}"
					"[event][id]" => "ID:01"
					"[rsa][message][id1]" => "ID:01"
					"[event][categoryid]" => "1604000000"
					"[logstash][fullDateTimeString]" => "%{fld8}"
					"[logstash][messagefound]" => true
				}
			}
			if [logstash][fullDateTimeString] {
				date { match => [ "[logstash][fullDateTimeString]", "M/d/yyyy H:m:s a" ] }
			}
		}
	}


################## END OF MESSAGES ##################

# End of the filter block
}


output {
#	if [logstash][headerfound] and [logstash][messagefound] {
#		elasticsearch {
#			hosts => ["https://elasticxxxxxx"]
#			index => "%{[observer][product]}-%{+YYYY.MM.dd}"
#			user => "logstash"
#			password => "abc"	# Better use keystore, cf https://www.elastic.co/guide/en/logstash/master/keystore.html
#			manage_template => true
#			template => "es-mapping-ncircleccmmsg.json"
#			template_name => "ncircleccm_template"
#			template_overwrite => true
#		}
#	} else {
#		# using a file output for logs that were not parsed correctly
#		# should you chose to send it to elasticsearch, please read https://discuss.elastic.co/t/latency-with-2-elasticsearch-systems/170074/2
#		file { path => "failed_logs-%{[observer][product]}-%{+YYYY-MM-dd}" }
#	}
	stdout {
		codec => rubydebug
	}
}
